# Developer Tools

chrome调试工具Developer Tools

- Elements

  文档dom树结构



- Console

  日志打印台

  

- Sources

  debugger打断点调试



- Network

  网络资源加载列表



- Application

  操作cookie，webstorage，indexDB等本地存储，也可以查看还有service workers等



- Performance

  可以观察从请求到渲染的完整过程（例如重绘回流所用时间等），可以通过调整网速来模拟不同环境。

  可以打开录制，会将页面变化的每一帧以及所用时间等信息记录下来

  

- Layers

  可以观察当前页面的图层（layer）



- Rendering

  将页面不同图层进行标记，例如可以将正在重绘的元素标绿



- 抓包

移动端h5页查看网络请求就需要使用到工具抓包，windows常用fiddler，mac常用charles

手机和电脑连接到同一个局域网，将手机代理到电脑上，手机浏览网页即可抓包。







# 请求优化点

- dns是否可以通过缓存减少dns查询时间
- 网络请求的过程走最近的网络环境
- 相同的静态资源是否可以缓存
- 能否减少http请求大小
- 减少http请求次数
- 服务端渲染





# 资源合并与压缩

资源不进行压缩合并，即使在开启keep-alive的情况下，请求与返回依然需要来往多次，会增加很多http往来延迟，并且文件不合并的话受网络丢包影响就更为严重，并且keep-alive经过代理服务器时可能被断开。

资源合并与压缩目的是：1.减少http请求数量，2.减少http请求数量大小。常见方式有：html压缩，css压缩，js压缩与混乱，文件合并，http请求中开启gzip压缩。



- html压缩

  html压缩是将浏览器无需识别的字符进行去除，例如空格，制表符，换行符，注释等。

1. 使用一些在线工具网站

2. nodejs提供了html-minifier工具

3. 使用后端模板引擎渲染压缩，例如ejs，可以利用普通的 JavaScript 代码生成 HTML 页面



- css压缩

  去除注释和重复或者无用的css代码

1. 使用在线网站工具
2. 使用html-minifier工具
3. 使用clearn-css对css进行压缩



- js的压缩与混乱

  删除无效字符，去除注释，代码语义的缩减与优化，将js代码进行混乱保护避免窥探。

1. 使用在线网站工具
2. 使用使用html-minifier工具
3. 使用uglifyjs2对js进行压缩



- 开启gzip

通过请求和响应头中增加Encoding字段，确定客户端或服务器端是否支持压缩
`Accept-Encoding: gzip`

`Content-Encodin:gzip`

举例，客户端发送请求，服务端压缩响应数据返给客户端

1、客户端请求中增加Accept-Encoding: gzip表示客户端支持gzip；

2、服务端接收到请求后，将结果通过gzip压缩后返回给客户端并在响应头中增加Content-Encodin:gzip 表示响应数据已被压缩

3、客户端接收请求，响应头中有Content-Encodin:gzip表示数据需解压处理

客户端也可以发送压缩数据给服务端，通过代码将请求数据压缩即可，规范起见同样要在请求中加入Content-Encodin:gzip



## 缺点

但资源合并依然存在自身的问题：1.首屏渲染问题。2.缓存失效问题（一个文件变动，合并后的整个文件都需要重新下载）。

所以资源合并建议

- 公共库合并
- 不同页面js分别打包成一个chunk（webpack异步加载）
- 灵活的决定这个文件是否合并





# 图片优化

## 格式

选择合适的图片格式来进行图片优化

- jpg有损压缩，压缩率比png高，但不支持透明



- png支持透明，使用tinypng网站来压缩图片

  png8：2^8色(8位2进制)+透明

  png24：2^24色，不支持透明

  png32：2^24色+透明（8位二进制单独支持透明）



- webp，2010年谷歌提出的图片格式，可以通过png/jpg转化，压缩和解码程度都高于jpg/png，但在ios webview中有兼容性问题。webp优势在于优秀的图像数据压缩算法，图片体积更小，质量却没有下降，同时具备有损和无损的压缩模式，Alpha透明以及动画的特性，在jpg/png的转化效果都非常优秀和稳定。

  

- svg，矢量图，代码内嵌描述图片，绘制能力有限，相对较小，可以绘制图片样式相对简单的图片



- canvas，位图（像素图），代码描述，手动绘制简单的图片



## 压缩

针对真实图片的情况，舍弃一些无关紧要的色彩信息来进行压缩

- css雪碧图：多张图片合并成一张，通过background-position调整位置获取图片

  优点：减少http请求数量

  缺点：单张图片如果过大，可能造成加载卡顿并且丢包后影响太大



- Inline-Image ：将图片内嵌到html中，例如base64格式

  优点：减少http请求数量

  缺点：base64会比原格式大三分之一



- 使用SVG矢量图或者iconfont字体图标来代替简单图片



- 使用tinypng网站压缩图片



- 使用webp



## 懒加载

懒加载是指等图片进入可是区域后再设置img-src属性去请求图片资源，减少无效资源加载，同一个域名下并发加载的资源有上限，并发加载图片过多会阻塞其他必要资源（例如script一般写在html底部）的加载。对其他资源也同理。

实现原理：给需要懒加载的图片节点设置为div，加上lazyload属性进行标记，然后将图片的src先缓存在div的data-image属性上，监听scroll事件等到标签进入视窗就在div中new一个Image子元素，将src属性设置为data-image属性缓存的值。

目前有一些库用来快速实现懒加载：Lazy Load，jQuery.lazyload等



```javascript
// 手撕懒加载
var viewHeight = document.documentElement.clientHeight // 获取可视区域高度
function lazyload() {
  // 选择出所有标记了lazyload和data-image属性的元素节点
  var eles = document.querySelectorAll('img[data-image][lazyload]') 
  Array.prototype.forEach.call(eles, function (item, index) {
    var rect = img.getBoundingClientRect() // 返回元素的大小及其相对于视口的位置。
		if(rect.bottom >= 0 && rect.top < viewHeight) {
      !function() {
        var img = new Image()
        img.src = item.dataset.image // 这个api是获取data-image属性值
        img.onload= function () {
          item. src = img.src
        }
        item.removeAttribute('data-image')
        item.removeAttribute('lazyload')
      }()
    }
  })
}

lazyload() // 首屏没有触发scroll事件，所以需要动手调用一次函数显示首屏图片

document.addEventListener('scroll', lazyload) // 绑定scroll事件
```



## 预加载

在带宽空闲时提前请求资源缓存下来，提高用户体验。

三种实现方式

- display: none，只请求不显示不影响渲染，进入视窗后再显示出来
- 预加载时new Image对象，进入视窗再插入
- 使用xmlhttpRequest对象

有preload.js库可以实现与加载





# 执行优化

html渲染有以下特点

- 顺序执行，外部资源资源可并发请求加载，但是对同一个域名，并发请求是有上限的

- 加载可能被脚本加载阻塞
- 加载可能存在依赖关系，例如html和css没有设置依赖关系，可能导致页面刚加载时只出现结构没有样式



## 顺序执行/并发加载

顺序执行：html读取时从上到下依次解析，解析出一个个词法单元token，然后开始顺序执行。

但是所有外部资源的请求都是并发家族的，不会等到运行到请求语句才开始请求，但是对一个域名下的并发请求是有上限的，所以实际业务中，资源会放在多个CDN域名下。



## css阻塞

css性能可能会让js变慢，是因为页面UI渲染和js解析线程会相互阻塞。

css应该和html存在依赖关系，html和css没有设置依赖关系，可能导致页面刚加载时只出现结构没有样式。将页面的css link放进head中可以阻塞页面的渲染，不会导致先渲染结构。并且css资源会阻塞js的执行但不会阻塞脚本的加载，也就是不阻塞加载，只阻塞执行，因为js可能会修改css属性。



## js阻塞

直接引入的script标签会阻塞页面的渲染，defer和async可以使脚本延迟执行，但js脚本并不阻塞资源的加载，因为加载资源的线程和执行js的线程不是同一个。js执行本身是单线程的，和渲染dom共用一个线程，所以js脚本会阻塞页面渲染和后续js脚本逻辑的执行。









# 重绘回流

可以通过chrome的Performance工具观察从请求到渲染的完整过程，可以通过调整网速来模拟不同环境。

页面渲染过程如下：

![页面渲染过程](./assets/页面渲染过程.png)





1.获取dom后分割为多个图层（layers）

2.对每个图层的节点计算样式结果（Recalculate style  样式重计算）

3.为每个节点生成图形和位置（layout  回流和重布局）

4.将每个节点绘制填充到图层位图中（Paint Setup和Paint 重绘）

5.图层作为纹理上传GPU

6.多个图层到页面上合成生成最终屏幕图像（Composite Layers 图层重组），在Painting阶段，会调用引擎的paint api（canvas会调用draw api）进行像素级信息计算与绘制，像素级信息具体表现为帧信息（图层），浏览器会将各层的信息发送给GPU（GPU进程：最多一个，用于3D绘制等），GPU会将各层合成（composite），最后显示在屏幕上。



- 回流/重排  reflow

当render树（css树和dom树生成render树）的因为部分元素尺寸，布局，隐藏等改变需要重新构建时，这就被称为回流或者重排（reflow），当页面布局和几何属性改变时就需要回流。回流一定触发重绘渲染到页面上，但重绘不一定触发回流。回流和重绘都会严重影响web性能。

触发回流需要元素的几何属性发生了改变：主要有盒子模型相关属性，定位以及浮动属性，改变节点内部文字结构

触发回流（**元素的几何属性**发生了改变）

1. 添加或删除可见的DOM元素
2. 元素位置改变
3. 元素本身的尺寸发生改变
4. 内容改变
5. 页面渲染器初始化
6. 浏览器窗口大小发生改变
7. offsetHeight， offsetWidth读取元素为了获取最新信息，会刷新浏览器的缓冲队列，造成回流



- 重绘 paint

当rander树的一些元素属性更新只影响元素的外观，不会影响布局的（例如color等），要将重新构建的渲染树渲染到屏幕上，这个过程就是“重绘”。







## 优化

1、浏览器自己的优化：浏览器会维护1个缓冲队列，把所有会引起回流、重绘的操作放入这个队列，等队列中的操作到了一定的数量或者到了一定的时间间隔，浏览器就会flush队列，进行一个批处理。这样就会让多次的回流、重绘变成一次回流重绘。



2、开发者的优化：我们要减少重绘和重排就是要减少对渲染树的操作，则我们可以合并多次的DOM和样式的修改。并减少对style样式的请求。

- transform代替top改变

  top会触发回流layout的过程，transform不会

  

- opacity替代visibility

  在一个单独的图层中：visibility触发重绘，opacity不会。如果没有将元素单独生成一个图层，opacity依然会触发回流和重绘



- 不要一条条修改dom样式，预先设置好class，然后修改dom的className属性



- 先把DOM离线后再修改，例如先把DOM给display: none(触发一次回流)，然后再修改多次，修改完后再显示出来，一共触发两次回流就能进行多次修改

- 不要把DOM节点属性值放进一个循环中当成循环的变量（每次查询dom也会浪费大量性能），应该提前缓存出来



- 不要使用table布局，table布局一个地方改了其他地方都会改变



- 动画实现的速度的选择，动画频率过高会导致频繁重绘回流并且js代码会被ui线程阻塞
- 为动画的html元素定位 position设置fixed 或 absolute ，那么修改他们的 CSS 不会触发回流
- 为动画新建图层
- 动画启用GPU加速



- offsetHeight或getComputedStyle之类的元素进行测量（会导致渲染队列强制刷新造成回流）

  





# GPU加速

在 DOM 树中每个节点都会对应一个 LayoutObject，当他们的 LayoutObject 处于相同的坐标空间时，就会形成一个 RenderLayers ，也就是渲染层。RenderLayers 来保证页面元素以正确的顺序合成，这时候就会出现层合成（composite），从而正确处理透明元素和重叠元素的显示。

某些特殊的渲染层会被认为是合成层（Compositing Layers），合成层拥有单独的 GraphicsLayer，而其他不是合成层的渲染层，则和其第一个拥有 GraphicsLayer 父层公用一个。

而每个GraphicsLayer（合成层单独拥有的图层） 都有一个 GraphicsContext，GraphicsContext 会负责输出该层的位图，位图是存储在共享内存中，作为纹理上传到 GPU 中，最后由 GPU 将多个位图进行合成，然后显示到屏幕上。需要进行复杂动画的元素（或所在元素）单独拥有一个合成图层交给GPU绘制可以大大提高性能

GPU适合对高密集的数据进行并行处理，CPU执行计算任务时，一个时刻只能处理一个数据，而GPU具有多个处理器核，在一个时刻可以并行处理多个数据，真正意义上实现了高并行。我们所说的GPU加速其实原理就是利用了GPU的高并行计算能力，比如我们在前端中利用GPU来处理复合图层（像素密集型）进行“加速”。

**简单来说：将频繁重绘回流的DOM元素单独作为一个图层（一般来说是动画），那么这个DOM元素的重绘和回流影响只会在这个图层当中，并且合成层的位图，会交由 GPU 合成，比 CPU 处理要快，这也就是GPU加速（硬件加速）原理**



- Chrome创建图层（开启GPU加速）的条件

chrome（webkit）有两种类型的层

RenderLayers 渲染层，这是负责对应 DOM 子树

GraphicsLayers 图形层，这是负责对应 RenderLayers子树。

可以通过chrome调试工具的Layers观察所有图层



**dom元素如何创建图层**

1. 3D或者透视变换css属性（perspective transfrom）的元素单独作为一个图层
2. 使用加速视频解码的`<video>`标签，视频播放是浏览器对视频每一帧都进行重绘，所以chrome将其单独作为一个图层
3. 拥有3D（WebGL）上下文或加速的2D上下文的`<canvas>`标签，这些节点大概率会频繁变换，所以chrome将其单独作为一个图层
4. 混合插件（例如flash）
5. 对自己的opacity做CSS动画或使用一个动画webkit变换的属性，拥有动画部分的元素也会单独作为一个图层
6. 拥有加速CSS过滤器的元素，例如translate3D（z轴）等会使用到GPU加速的属性的元素都会单独作为一个图层
7. 元素有一个包含复合层的后代节点，就是一个元素拥有一个子元素，该子元素在自己的层里
8. 元素有一个z-index较低并且包含一个复合层的兄弟元素，就是该元素在复合层上面渲染。也就是有z-index属性又有兄弟节点。

常用dom元素提升图层的方式有transform: translateZ(0)，或者设置CSS 的 will-change属性。 will-change 可以设置为opacity、transform、top、left、bottom、right。



提升到合成层后合成层的位图会交GPU处理，但仅仅只是合成的处理（把绘图上下文的位图输出进行组合）需要用到GPU，生成合成层的位图处理（绘图上下文的工作）是需要CPU。但是图层合成（Composite阶段）依然有需要占用大量内存的问题，也会造成层爆炸问题（很多不需要提升为合成层的元素因为某些不当操作成为了合成层）。

解决层爆炸的问题，最佳方案是打破 overlap 的条件，也就是说让其他元素不要和合成层元素重叠。简单直接的方式：使用3D硬件加速提升动画性能时，最好给元素增加一个z-index属性，人为干扰合成的排序，可以有效减少创建不必要的合成层，提升渲染性能，移动端优化效果尤为明显。提升合成层的最好方式是使用 





# SSR

前端渲染需要在前端加载框架，然后加载js代码，最后渲染成html页面，可能会造成首屏性能问题，SSR是直接在后端生成渲染好的html页面，发送给客户端。

   服务端渲染的优点：
   　1.首屏渲染快
       2.利于SEO
　服务端渲染的缺点：
       1.不容易维护，通常前端改了部分html或者css，后端也需要修改。
       2.会增加项目整体复杂度（前后端耦合，互相依赖 (较高的学习成本)）。
       3.库的支持性（兼容性）
       4.对服务器压力较大

SSR框架和前端框架也有一些区别，例如vue的ssr中没有mounted这个生命周期。所以原本的vue代码不能直接在SSR中使用。