# 计算机网络

# Fiddler

Fiddler可以截获浏览器发送和接收的HTTP请求与响应

# OSI七层模型与五层模型

OSI（Open System Interconnect），即开放式系统互联。 一般都叫OSI参考模型

## 七层模型

- 7-应用层

- 6-表示层

- 5-会话层

- 4-运输层

- 3-网络层

- 2-数据链路层

- 1-物理层

## 五层模型

自顶向下

- 应用层

  **应用层**的功能，就是用来规定应用程序的数据格式的。每个应用需要什么数据在这一层规定

  HTTP协议在这一层

  

- 传输层

  传输层的功能就是建立**端口到端口**的通信。负责将数据传输到具体的端口让应用接收。

  TCP/UDP协议在这一层

  

- 网络层

  IP协议，ARP协议在这一层，网络层的功能是建立**主机到主机**的通信

  设备主要有：**网络适配器**

  

- 数据链路层：

  负责让计算机读懂电缆传过来的0与1传送规则，例如以太网协议，MAC地址，广播与ARP协议等在这一层

  设备有：网桥、网卡、以太网交换机

  

- 物理层：

  光纤，电缆等物理层面上的连接设备，实现0、1信号的传输。



# Web

Web是一种基于超文本（html）和HTTP的，全球性的，动态交互的跨平台分布式图形信息系统，是建立在Internet上的网络服务，，是图形化的直观界面（而不是枯燥的HTTP报文），Web上的文档和超链接将Internet组成了一个互为关联的网状结构。

# TCP/IP简介

TCP：https://www.jianshu.com/p/ef892323e68f

Tcp/IP是两个不同的协议，即传输控制协议/网际协议。

Tcp在传输层，用于传输数据

IP在网络层，用于定位服务器。

## TCP

TCP是传输层的一种协议，可靠，但数据量大，要经过三次握手才能连接

UDP可以无需连接，就发送协议，但不可靠容易丢包

## IP

公网ip地址每台设备都是唯一的。IP地址由两部分组成，一部分为网络地址，另一部分为主机地址。

ipv4地址由4个字节组成，每个字节是8位2进制，为了方便观看转换为十进制表示，255就是二进制中的11111111，每位称为一个掩码，4个字节共32位掩码。IPV4地址：` 1.1.1.1~255.255.255.255 ` 之间，目前ipv4地址已经用完。

ipv6地址由16个字节组成，共128位掩码



## URI

HTTP使用统一资源标识符**URI**（Uniform Resource Identifiers, URI）来传输数据和建立连接。URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息。URI是标识这个资源是什么。

```
Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的
 URI一般由三部组成：
 ①访问资源的命名机制
 ②存放资源的主机名
 ③资源自身的名称，由路径表示，着重强调于资源。
```

而**URL**,全称是UniformResourceLocator, 中文叫统一资源定位符,是互联网上用来标识某一处资源的地址。URL则是表明这个资源在哪。笼统地说，每个 URL 都是 URI，但不一定每个 URI 都是 URL。采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。

```
采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。URL一般由三部组成：
 ①协议(或称为服务方式)
 ②存有该资源的主机IP地址(有时也包括端口号)
 ③主机资源的具体地址。如目录和文件名等
```

通俗地说，URL是Internet上描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上。URN则是永久统一资源定位符。

URL/URN是URI概念的一种实现方式。



## URL

例如`http://www.aspxfans.com:80/news/index.asp?boardID=5&ID=24618&page=1#name`

1. **协议部分**：该URL的协议部分为“http”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在"HTTP"后面的“//”为分隔符。
2. **域名部分**：URL的域名部分为`www.aspxfans.com`。一个URL中，也可以使用IP地址作为域名使用。
3. **端口部分**：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，默认的HTTP服务端口就是80。
4. **虚拟目录部分**：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”。
5. **文件名部分**：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名。
6. **锚部分（hash）**：从“#”开始到最后，都是锚部分，也叫hash部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分。url中#后面的部分叫hash部分，hash的变化会触发网页跳转，即可以浏览器前进后退，但是hash变化不会刷新页面，**这是SPA的必须的特点**，并且hash永远不会提交到服务端。

7. **参数部分**：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。例如参数`boardID=5&ID=24618&page=1`。参数可以允许有多个参数，参数与参数之间用“&”作为分隔符。



## URN

URN永久统一资源定位符，URL中的资源移动了位置，这个URL就失效了，如果使用URN，资源移动位置，URN还是能找到该资源的位置



# TCP/IP协议族

- TCP/IP其实是一系列跟互联网相关的协议集合总称
- 分层管理是TCP/IP协议的重要特征

TCP/IP协议族由四层协议组成：应用层，传输层，网络层，数据链路层

- 应用层 HTTP

- 传输层 TCP

- 网络层 IP

- 链路层 网络

数据发送自上而下每经过一层都会打上一层对应的首部信息，数据接收时又会逐层把首部信息删除掉

例如应用层发出HTTP数据包

经过传输层，会被打上TCP首部，此时数据封装为TCP包`{TCP首部+HTTP数据}`

经过网络层时，会被打上IP首部（例如端口号等），数据变为`{IP首部+TCP首部+HTTP数据}`

经过链路层，会打上以太网首部，此时数据变为`{以太网首部+IP首部+TCP首部+HTTP数据}`

到达对方计算机后又会自下而上逐层解包删去首部，到应用层后只剩下HTTP数据

## 应用层

应用程序在应用层通过系统调用来跟传输层进行通信

## 传输层

- 传输层通过系统调用向应用层提供两台计算机的数据传输功能
- 传输层有两个协议：TCP和UDP

## 网络层

网络层处理网络上流动的数据包，数据包是网络传输最小单位，网络层规划通过怎样的路径让数据包传输到了另外一台计算机

## 链路层

链路层是处理连接网络的硬件部分，包括网卡，驱动，光纤等



# TCP/UDP

UDP支持一对一，一对多，一对全的通信。UDP首部仅验证端口，并且不保证数据可靠，所以首部很小。

- 无连接
- 支持一对一，一对多，一对全的通信
- 将应用层交付的报文直接打包
- 没有流量控制，拥塞控制，不可靠
- 首部开销小，仅8字节



TCP必须三报文握手建立连接通信，所以TCP只只支持一对一通信，TCP协议支持流量控制，拥塞控制等，所以首部很大。

- 面向连接
- 只能一对一通信
- 面向字节流
- 可靠传输，实现了流量控制和拥塞控制
- 首部最小20字节，最大60字节



# 流量控制

A给B发送数据，B会根据自己的接收缓存，会对A进行定量的流量控制（根据B的接收窗口对A进行流量控制），**A的滑动窗口值会设置为为B设置的接收窗口值与自身拥塞控制窗口取较小值**，A每发送完当前滑动窗口的数据就需要等B回复确认收到（保证这些数据没有丢失）和B新的接收窗口值。

一旦A收到了B的确认，滑动窗口（大小为返回的新接收窗口值与自身拥塞控制窗口取较小值）就会向后滑动，之前被确认成功发送了的数据缓存就可以删除了。如果中间某一次传输数据丢失了，B就不会对这段数据返回确认，A等待超过一定时间就会将当前滑动窗口内的数据重发。（超时重传）

B返回的流量控制值可能为0（零窗口通知，将A的滑动窗口设置为0，A就无法发送数据了），意思是要A暂时停止发送数据，因为B的接收缓存不足了。



但有一种特殊情况，B暂停A的发送，过一段时间B接收缓存空闲了，向A发送带有新的流量控制值的消息恢复发送，但是这条信息丢失了。那双方就会一直互相等待造成死锁。

为了解决上面的问题，TCP为每条连接设定了一个持续计时器，只要TCP连接的任意一方接收到了暂停发送的零窗口通知，就启动这个计时器，如果计时器超时，就向对方发送一个**零窗口探测报文**，仅携带一字节数据，而对方在确认这个探测报文段时，给出自己现在的接收窗口值，如果还是零，则重置计时器重新计时，如果不是零，则根据新的接收窗口值重新滑动窗口发送数据。当然这个零窗口探测报文也有超时重传计时器，防止零窗口探测报文丢失。



# 拥塞控制

对网络某一资源的需求超过了该资源所能提供的可用部分，网络性能就会变坏，这种情况叫拥塞

TCP拥塞控制一共有四种算法

- 慢开始  	

  拥塞窗口从1开始，指数增长

  

- 拥塞避免 

   拥塞窗口线性加1，发生拥塞后（超时重传）将慢开始门限降低为一半，拥塞窗口重置为1重新执行慢开始

   

- 快重传   

    连续三次收到同一报文段丢失的确认，其他报文段正常，则等待超时，立刻重传避免超时重传执行慢开始  

    

- 快恢复

  将慢开始门限降低为一半，拥塞窗口也重置为一半并继续执行拥塞避免算法线性+1（而不是慢开始重置为1）
  
  

TCP发送方维护一个叫拥塞窗口cwnd的状态变量，其值取决于网络的拥塞程度并且动态变化（判断依据是是否按时收到报文，即没有出现超时重传），如果网络顺畅，拥塞窗口就大一些，如果网络出现拥塞，拥塞窗口就小一些。

然后发送方还会设置一个慢开始门限ssthresh状态变量

当cwnd < ssthresh 时，采用慢开始算法

当cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法

当cwnd ， ssthresh 相等时，慢开始和拥塞避免都可以



## 慢开始

​		发送方先发送一个1个报文段（0-1），收到接收方确认报文段后，下次发送发送2个报文段（1-2），再次收到接收方确认报文段后，下次发送4个报文段（3-6），接收方再次发送确认报文段，发送方下次又发送8个报文段......发送方发送的报文段呈指数上升，直到发送的报文段数量等于慢开始门限ssthresh后进入拥塞避免算法



## 拥塞避免

​		慢开始算法每次增加的报文数呈指数上升，但进入拥塞避免算法后每次发送增加的报文数只能加1，按线性加一的规律增大每次发送的报文数。

​		持续加1后如果某一次发送丢失，发生超时重传，此时判断了拥塞，此时将慢开始门限值（ssthresh）规定为发生拥塞的一半，并将拥塞窗口cwnd降低为1，重新开始慢开始算法，到达新的慢开始门限值后重新开始拥塞避免算法....如此循环直至发送完毕。



## 快重传

​		有时，个别报文段会在网络中丢失导致发送方超时重传，但此时网络没有拥塞，发送方误以为发送拥塞，重新开始慢开始算法，降低了传输效率，采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失，快重传的意思是让发送方立马进行重传，而不是等计时器超时再重传。

​		这要求接收方不要等自己发送数据时才捎带确认，而是立即发送确认，即使后来收到了失序的报文段也要对已收到的报文段重复确认，发送方一旦收到三个重复确认，就将相应报文段立刻重传，而不是等带报文段的计时器超时再重传。例如2号报文段丢失，发送方发送3号报文段，接收方发现2号没收到，发送一次3号收到2号没收到的确认，发送方先不予理会，继续发送4号报文段，接收方发现2号还是没收到，继续发送一条4号收到2号没收到的确认，发送方继续发送5号报文段，接收方发送5号收到2号没收到的确认，至此已经连续三次收到2号没收到的确认，发送方立刻进行对2号报文段的重传，而不是等计时器超时再重传。

​		对于个别丢失的报文段，发送方不会采取超时重传，也就不会误以为发生拥塞采取慢开始算法了，而是采取快恢复算法



## 快恢复

将慢开始门限ssthresh和拥塞窗口cwnd调整为当前的一半（慢开始是将拥塞窗口降低为1），开始执行拥塞避免算法







# TCP三次握手

![tcp](.\assets\tcp.jpg)

使用TCP协议进行通信的双方必须先建立连接然后才能开始传输数据，为了确保连接双方的可靠性TCP协议采用了三次握手策略，TCP 的可靠连接是靠 **seq**（ sequence numbers 序列号）来达成的，而因为每个包都是有序列号的，所以都能被确认收到这些包。

tcp标志位

SYN	(synchronous建立联机)

ACK	(acknowledgement 答复确认)

seq	(Sequence number序列号码)  



- 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认

  第一次握手是客户端向服务端发送请求，第一次握手，服务端接收到了客户端信息，服务端知道了自己的接收能力正常，客户端发送能力正常

  

- 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。

  第二次握手是服务端接收到请求，向客户端发送一次回应，第二次握手，客户端收到回应后，客户端知道了自己的收发能力正常，服务端收发能力也都正常，但此时服务端不知道客户端接收能力是否正常，也不知道自己的发送能力是否正常。

  

- 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

  第三次握手是客户端再向服务端发起一次握手，服务端收到第三次握手后，知道客户端收到了自己的响应，服务端知道了自己发送能力正常，客户端接收能力正常。

经过三次握手后，客户端Client和服务端Serve都知道了对方和自己的收发能力正常，可以开始传输数据了





**三次握手的目的是为了防止已失效的连接请求报文段（第一次握手）突然又传送到了服务端，如果没有第三次握手再次确认的话，服务器不知道客户端是否接收正常，服务器又会尝试去建立连接，因而产生错误，浪费了服务器资源**





# TCP四次挥手

![四次挥手](.\assets\四次挥手.png)

第一次挥手客户端发起，客户端发送消息告诉服务端要关闭连接

第二次挥手服务端向客户端发送**回复应答报文**，第二次挥手后客户端已经无法向服务端发送消息，但服务端可能还有数据没有发送完，所以继续向客户的发送数据

数据发送完毕后，服务端向客户端发起第三次挥手关闭服务端到客户端的连接

第四次挥手客户端向服务端发送**回复应答报文**，结果2MSL如果客户端没有收到回复，证明服务端已经关闭通信，此时TCP连接彻底断开



第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，**客户端进入FIN_WAIT_1状态。**意思是说"我客户端没有数据要发给你了"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。

第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。**这个时候客户端就进入FIN_WAIT_2 状态**，继续等待服务器端的FIN报文。

第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。**服务器端进入LAST_ACK状态。**

第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后**进入TIME_WAIT状态**，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。



第四次挥手等待2MSL的原因：如果Client（客户端）直接CLOSED（关闭），然后又再向Server（服务器端）发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，**如果前一次连接的某些数据仍然滞留在网络中**，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，于是，TCP协议就认为那个延迟的数据是属于新连接的，**这样就和真正的新连接的数据包发生混淆了**。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。





# DNS

​		ip地址难以记住并且做了负载均衡的服务器，可能不同区域拥有不同的ip地址，所以使用统一的域名，再转换为ip地址。

​		DNS提供域名到IP地址之间的解析服务，因为TCP/IP协议根据IP地址进行访问的，所以我们需要将域名通过DNS服务器转换为IP地址，拿到IP地址后才能建立TCP连接。

​		DNS主要用UDP协议通信，但是当请求字节过长超过512字节时用TCP协议，将其分割成多个片段传输。DNS协议端口号为53.

​		客户端会优先找离自己最近的CDN服务器，让他解析域名，CDN缓存在运营商提供的机房，里面对很多热门网站都的静态资源进行了缓存，如果这个服务器找不到对应的IP地址，才会向再上一级DNS服务器寻找，一直寻找到全球最高级根DNS服务器。最后如果还找不到就返回域名错误。



**1.DNS查询过程：**

​         1）浏览器缓存：浏览器会按照一定的频率 缓存DNS记录，chrome对每个域名会默认缓存60s；IE将DNS缓存30min；Firefox默认缓存时间只有1分钟；Safari约为10S。

 　　2）操作系统host文件缓存：如果浏览器缓存中找不到需要的DNS记录，就会取操作系统中找，window缓存时间为一天

　　 3）路由缓存：路由器也有DNS缓存

　　 4）ISP互联网服务提供商（Internet Service Provider）的DNS服务器

　　 5）根服务器：ISP的DNS服务器找不到之后，就要向根服务器发出请求，进行递归查询



**2.用什么解析成IP？**

从网址到IP地址的转换，称为DNS解析，DNS解析是一个递归查询的过程，具体步骤如下（以www.google.com为例）：

（1）首先在本地域名服务器（最近的一台DNS服务器）中查询IP地址

（2）如果没有找到，本地域名服务器会向根域名服务器发送一个请求

（3）如果根域名服务器中也不存在该域名，但判定这个域名属于“com”域，则本地域名服务器会向com顶级域名服务器发送一个请求

（4）如果com顶级域名服务器没有找到该域名，但判定这个域名属于“google.com”域，则本地域名服务器会向google.com域名服务器发送一个请求，以此类推

（5）直到本地域名服务器得到域名对应的IP地址，并将其缓存到本地，供下次查询使用

（6）综上，网址的解析过程为.->.com->google.com->www.google.com.。



# CDN

CDN，内容分发网络，CDN能够缓存JavaScript脚本，css样式表，图片，图标，Flash等静态资源文件（不包括html页面），这些静态资源文件的访问频率很高，将其缓存在CDN可以极大地提高网站的访问速度，但由于CDN是部署在网络运营商的机房，所以在一般的网站很少用CDN加速。

CDN（内容分发网络），它通过避开互联网上有可能影响传输速度与稳定性的缓解，使传输更快更稳定。

简单来说，就是将静态资源缓存到离用户很近的一个CDN节点上，不必千里迢迢去访问服务器，这样不仅能提高用户的访问速度，也能减少服务器的带宽消耗，降低负载。

不同地区的用户会访问到离自己最近的相同网络线路上的CDN节点，当请求达到CDN节点后，节点会判断自己的内容缓存是否有效，如果有效，则立即响应缓存内容给用户，从而加快响应速度。如果CDN节点的缓存失效，它会根据服务配置去我们的内容源服务器获取最新的资源响应给用户，并将内容缓存下来以便响应给后续访问的用户，这就意味着一个地区的用户只需要访问一次服务器，后续的用户都能因此受益。



那么，各地区用户明明访问的是同一个域名，为什么能访问的不同的CDN节点呢？

![](https://images2018.cnblogs.com/blog/1044429/201711/1044429-20171129135006956-1447658142.png)

由上述示意图可知，这有赖于服务商提供的智能域名解析服务，浏览器发起域名查询时，这种智能DNS服务会根据用户IP寻找离他最近的CDN节点IP，引导浏览器与此节点连接。



cdn应用范围:

cdn多用于静态资源，例如js文件、图片、css文件。。以及静态页面，页面可分为静态页面和动态页面（当收到用户请求时服务器会在服务端对页面进行一次后台渲染把数据渲染到页面之后再返回给用户的页面），cdn并不适用于动态页面。

 

由此可得出两个优化建议:

1.由于有多个运营商，将静态资源部署到不同网络线路的服务器中，即根据运营商（网通、电信。。）来分配静态资源，这样能提高缓存失效时溯源的速度

2.加载静态资源时使用与页面不同的域名，一方面能便于接入为CDN而设置的智能DNS解析服务，另一方面由于两者不同域，这样加载静态资源的HTTP请求就不会带上主页面的cookie等数据，减少了数据传输量，进一步加快了网络访问。

 

进一步优化:

浏览器对同一ip进行请求的最大并发连接数是不一样的：IE11 、IE10 、chrome、Firefox 的并发连接数是 6个，IE9是10个

如果页面静态资源（图片等）过多（大于6个）会存在资源请求等待的情况。目前现实状况是大多用户带宽越来越大，但是咱们的静态资源并非那么大，很多文件都是几k或者几十k，6个文件加起来都小于带宽。这样就导致了资源的浪费。解决方案是：用多个不同IP的服务器来存储这些文件，并在页面中通过绝对路径的方式引用（要求同一IP的文件不超过6个）。这样就可以尽可能的减少资源请求等待的情况。



# HTTP简介

**HTTP超文本传输协议。他运行将超文本标记语言（html）文档从web服务器返回客户端浏览器。**

HTTP是从服务器传输超文本到本地的传送协议，位于应用层。一次http请求（request）只会返回一个响应（response）。

HTTP是基于TCP/IP通信协议（是TCP/IP的一个子集）来传输数据，属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。

HTTP协议工作于客户端-服务端架构上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。



## 特点

1. **简单快速**：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
2. **灵活**：HTTP允许传输任意类型的数据对象。正在传输的类型由请求头中的Content-Type标记。
3. **无连接**：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
4. **无状态**：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 所以出现了cookie和session两种技术用于保存状态。
5. 支持 `B/S(浏览器/服务器模式) `及 `C/S（客户端-服务器）`模式。



## HTTP历史版本

HTTP/0.9

只有GET请求

没有请求头等描述数据的信息

服务器发送完毕就关闭tcp连接



HTTP/1.0

新增了POST,HEADER等请求方式

增加了状态码status code和请求头

多字符集支持，多部分发送，权限，缓存等



HTTP/1.1

支持持久连接

pipeline ，可以在一个TCP连接里发送多个HTTP请求，但是发送顺序和返回顺序必须一致，也就是后面的请求已经处理好了，前面的请求还么处理好，后面的处理结果也无法提前返回。HTTP/2.0修复了这个问题。

增加host和其他字段



HTTP/2.0

所有数据以二进制传输

同一个连接里发送多个请求，返回不用按照顺序来，处理好了即可返回。

增加请求头信息压缩以及推送（服务端主动发送消息）等提高效率的功能






# HTTP请求报文Request

客户端发送一个HTTP请求到服务器的请求消息包括以下格式：

**请求行（request line）、请求头（header）、空行和请求体四个部分组成。**



## 请求行

**请求行**由请求方法，URL，协议版本信息组成。

HTTP请求的数据部分主要由**请求头（放置请求信息）**+ **请求体（一般放置post请求表单提交请求数据）**组成。

一般get发送的表单数据直接放进url中，post请求则将表单数据放进请求体。

HTTP请求中URL的端口号默认为80端口。

```javascript
GET /562f25980001b1b106000338.jpg HTTP/1.1  
Host    img.mukewang.com
User-Agent    Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36
Accept    image/webp,image/*,*/*;q=0.8
Referer    http://www.imooc.com/
Accept-Encoding    gzip, deflate, sdch
Accept-Language    zh-CN,zh;q=0.8,en-us,en;q=0.3//中文权重比英文高

//一个Get请求
//第一部分为请求行，包含请求方法GET，URL，协议版本信息HTTP/1.1
//第二部分 请求头部，紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息
//第三部分空行请求头部后面的空行是必须的
//即使第四部分的请求数据为空，第三部分也必须有空行
//第四部分请求体，get请求一般为空
```

```javascript
POST / HTTP1.1
Host:www.wrox.com
User-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)
Content-Type:application/x-www-form-urlencoded
Content-Length:40
Connection: Keep-Alive

name=Professional%20Ajax&publisher=Wiley
//一个post请求
//第一部分：请求行，第一行明了是post请求，以及http1.1版本。
//第二部分：请求头部，第二行至第六行。
//第三部分：空行，第七行的空行。
//第四部分：请求数据，第八行。
```

### 常用HTTP请求方式

- GRT
- POST
- PUT
- HEAD
- DELETE
- OPYIONS
- TRACE
- CONNECT

## 请求头

每个HTTP请求和响应都会带有相应的头部信息。默认情况下，在发送XHR请求的同时，还会发送下列头部信息：

属性后可以跟`q=`，后面数字代表权重

- **Accept  浏览器能够处理的内容类型** 

  ```
  text/html	可以处理html超文本
  */*			可以处理所有类型文件
  ```

- **Accept-Charset  浏览器能够显示的字符集**

- Accept-Encoding：指定报文主体的传输编码方式，例如gzip

  ```
  支持的压缩方法
  gzip
  deflate
  ```

- Accept-Language 浏览器当前设置的语言

  ```
  zh-CN,zh	中文
  en-us,en	英文
  ```

- **Connection**  **浏览器与服务器之间连接的类型**

  ```
  kkep-alive	
  暂时不关闭传输HTTP数据的TCP连接，如果客户端再次访问这个服务器的页面会继续使用这套连接
  
  close
  代表一次请求完成后，会关闭TCP连接，如果客户端下次还需要发送请求，需要重新建立TCP连接
  ```

- **Cookie  当前页面设置的任何Cookie**

- **Host  发出请求的页面所在的域**

  ```
  域主要用于指定被请求资源的internet主机和端口号
  通常从HTTP URL中提取出来
  
  url为 http://www.wrox.com:8080
  则提取出来的域为Host www.wrox.com:8080
  ```

- **Referer   发出请求的页面的URL**

  ```
  告诉服务器请求是从哪个页面链接点击过来的
  服务器会借此得到一些信息
  ```

- **User-Agent   浏览器以及操作系统信息**

  ```
  告诉服务器，客户端所使用的浏览器以及操作系统的名称与版本
  通过User-Agent设计浏览器兼容
  ```

- **Content-Type  说明了报文体内对象的媒体类型**

  一般post请求才有报文体
  
     text/html ： HTML格式
  
     text/plain ：纯文本格式      
  
     text/xml ：  XML格式
  
     image/gif ：gif图片格式    
  
     image/jpeg ：jpg图片格式 
  
     image/png：png图片格式
  
     application/xhtml+xml ：XHTML格式
  
     application/xml     ： XML数据格式
  
     application/atom+xml  ：Atom XML聚合格式   
  
     application/json    ： JSON数据格式
  
     application/pdf       ：pdf格式  
  
     application/msword  ： Word文档格式
  
     application/octet-stream ： 二进制流数据（如常见的文件下载）
  
     application/javascript  ： js代码
  
     multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式
  
     application/x-www-form-urlencoded：表单提交信息


## 请求体

包含了post请求的请求消息





# HTTP响应报文Response

一般情况下，服务器接收并处理客户端发过来的请求后会返回一个HTTP的响应消息。

**HTTP响应也由四个部分组成，分别是：响应行、响应头、空行和响应体。**

而响应消息的数据部分也由**响应头**和**响应体**组成。例如我们返回的HTML代码就放进响应体中

```
HTTP/1.1 200 OK
Date: Fri, 22 May 2009 06:07:21 GMT
Content-Type: text/html; charset=UTF-8

<html>
      <head></head>
      <body>
            <!--body goes here-->
      </body>
</html>

第一部分：状态行，由HTTP协议版本号， 状态码， 状态消息 三部分组成。
第二部分：第二行第三行为消息报头，用来说明客户端要使用的一些附加信息如时间，cookie等
第三部分：空行，消息报头后面的空行是必须的
第四部分：响应正文，服务器返回给客户端的文本信息。空行后面的html部分为响应正文。
```



## 响应行

状态行，由**HTTP协议版本号**， **状态码**， **状态消息** 三部分组成。

HTTP协议版本号就是当前协议的版本号HTTP/1.1

状态代码有三位数字组成，第一个数字定义了响应的类别，共分五种类别:

**1xx：指示信息--表示请求已接收，继续处理**

**2xx：成功--表示请求已被成功接收、理解、接受**

**3xx：重定向--要完成请求必须进行更进一步的操作**

**4xx：客户端错误--请求有语法错误或请求无法实现**

**5xx：服务器端错误--服务器未能实现合法的请求**



### 常见状态码

状态码		状态消息

200 			OK							   	//客户端请求成功  

400 			Bad Request 				//客户端请求有语法错误，不能被服务器所理解

401 			Unauthorized            	//请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 

403 			Forbidden                	 //服务器收到请求，但是拒绝提供服务  

404 			Not Found                 	//请求资源不存在，eg：输入了错误的URL  

500 			Internal Server Error    //服务器发生不可预期的错误 

503 			Server Unavailable       //服务器当前不能处理客户端的请求，一段时间后可能恢复正常



## 响应头

HTTP响应头部信息：

- Date：表示消息发送的时间，时间的描述格式由rfc822定义
- Server：服务器名字。
- Connection：浏览器与服务器之间连接的类型
- Content-Encodin，响应请求头的编码类型，例如gzip
- Content-type：表示后面的文档属于什么类型，text/html ： HTML格式，text/plain ：纯文本格式等
- Cache-Control：控制HTTP缓存
- 也可以添加自定义信息



## 响应体

响应体中包含了服务器响应给客户端的具体数据





# HTTP请求方法

HTTP/1.0

- GET
- POST
- HEAD

HTTP/1.1

- PUT
- DELETE
- OPTIONS
- TRACE
- CONNECT



## HTTP请求方法

根据HTTP标准，HTTP请求可以使用多种请求方法，但常用的还是POST和GET。

 HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。

 HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。

- GET：求指定的页面信息，并返回实体主体。

  请求的数据会附在URL之后（就是把数据放置在HTTP协议头中），以?分割URL和传输数据，多个参数用&连接；

  如果数据是英文字母/数字，原样发送，如果是空格，转换为+；

  如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII;

  特定浏览器和服务器对URL长度有限制，例如 IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系 统的支持;

  

- POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改;

  由于不是通过URL传值，理论上数据不受限。但实际各个WEB服务器会规定对post提交数据大小进行限制

  

- HEAD

- OPTIONS



## GET

GET方法用来请求已被URI识别的资源，指定资源经过服务器解析后返回response结果给客户端，一般get方法用于查资源

GET方法可以传输一定数据，但是采用明文传输，GET请求传输的信息会明文拼接在HTTP请求的URL上

所以GET方法请求传输信息不能太大，每个浏览器都会对URL长度有一定限制（浏览器通常都会限制url长度在2K个字节），而且明文传输存在安全隐患



## POST

POST方法与GET类似，用于传输数据，比如提交表单等

POST将传输的信息放入HTTP请求的请求体中

两个相同的Post请求，后一个请求不会把第一个请求覆盖掉，所以Post往往用来增资源



## PUT

PUT是客户端向服务器传送数据用以取代指定的文档的内容，也就是用户上传一些数据来替换掉服务端的一些数据

PUT和POST传输方式类似，但最大的不同是，PUT是**幂等**的，而POST不幂等

幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变

简单来说，如果两个PUT请求相同，后一个请求会把第一个请求覆盖掉，所以PUT用来改资源

**因此，我们更多时候创建对象的时候用POST，更新对象用PUT**

但PUT方法有一定安全隐患（没有验证机制），所以大部分web网站还是采取POST传输对象，然后再在后端更新对象



## HEAD

HEAD请求和GET请求几乎相同，只不过请求消息中不需要带有请求头信息，而且返回的response中也没有具体消息，只有响应头，一般用作验证能够成功连接服务器，因为HEAD对客户端和服务端消耗都极小，常用于检测超链接可用



## DELETE

请求服务器删除指定资源

但DELETE方法同样没有验证机制，所以不常使用



## OPTIONS

用来查询针对请求URI指定的资源支持的方法，返回值是服务器支持的访问方法，比如会返回支持POST方法，GET方法等





# HTTP响应状态码

用于表达服务器超文本传输协议响应状态的三位数字代码

**1xx：指示信息--表示请求已接收，继续处理，这类响应一般是临时响应，只包含状态行，响应头和空行，响应体中没有消息**，这个类型不太常用

**2xx：成功--表示请求已被成功接收、理解、接受**

​		200   	ok   					  请求已成功，数据成功随响应头，响应体返回

​		202		Accepted		    已接收请求，但未处理完成（例如需要排队等待）

​		206		Partial Content  服务器成功处理部分请求 （例如断点续传）

**3xx：重定向--要完成请求必须进行更进一步的操作，后续请求地址（重定向目标）在本次响应的Location域中指明**

​	    301		Moved Permanently	请求资源已经被永久移动到新URI，响应消息内返回新的URI，浏览器会自动跳转，且下次访问都会使用新URI

​	    302		Found		资源临时移动，客户端应使用原有URI，例如我们需要使用第三方登陆，会临时去新URI进行一些操作

​	    304        缓存，304 的标准解释是：客户端有缓冲的文档并发出了一个条件性的请求。服务器告诉客户端，原来缓存的文档还可以继续使用。

**4xx：客户端错误--请求有语法错误或请求无法实现，例如资源丢失等**

​		400	Bad Request	客户端请求的语法错误，服务器无法理解本次请求

​		401	Unauthorized  请求要求用户进行身份验证

​		403	Forbidden		服务器理解本次请求，但拒绝执行请求，例如权限不足

​		404	Not Found		服务器无法根据客户端请求找到资源

**5xx：服务器端错误--服务器未能实现合法的请求**

​		500	Internal Server Error   服务器内部错误，无法完成本次请求

​		502	Bad Gateway				充当网关或者代理的服务器，从远端服务器接收到了一个无效的请求

​		503    Server Unavailable      服务器当前不能处理客户端的请求，一段时间后可能恢复正常



#	Cookie与Session

HTTP本身无状态无记忆，优点在于解放了服务器，但每次需要以前的信息时都需要重传，这样会导致服务器压力增大，所以使用了Cookie与Session两种技术分别在客户端和服务端保存状态信息。

如果cookie和session核对成功，就可以验证状态。

而且更安全的措施是将cookie进行完全加密，只有服务端能读懂。



# Cookie

Cookie实际上就是一小段文本信息，客户端请求服务器，如果服务器需要记录该用户状态，就给客户端浏览器颁发一个cookie。

客户端浏览器将cookie保存起来，当浏览器再请求该网站时，浏览器就把请求网站连同cookie一同提交给服务器，服务器检查该cookie来辨认用户状态。

生成cookie字符串的头部字段是Set-Cookie，并且这个字段可以设置多个，或者设置成一个数组，不会被覆盖，发送时会合并成一个字符串

使用Cookie流程

1. 用户提交用户名和密码的表单，这通常是一个POST HTTP请求。
2. 服务器验证用户名与密码，如果合法则返回200（OK）并设置 Set-Cookie 为 authed=true 。
3. 浏览器存储该Cookie。
4. 浏览器发送请求时，设置`Cookie`字段为 authed=true 。
5. 服务器收到第二次请求，从`Cookie`字段得知该用户已经登录。 按照已登录用户的权限来处理此次请求。

```javascript
res.writeHead(200, {
  'Content-Type': 'text/html;charset=utf-8',
  'Set-Cookie': 'id=123;max-age=10',
  'Set-Cookie': 'age=18'
  //'Set-Cookie':['id=123;max-age=10', 'age=18']
})
```



## Cookie属性

cookie的属性直接写进字符串中`'Set-Cookie': 'id=123;max-age=10'`

max-age是设置过期时间（多少秒后过期）

expires字段是设置过期日期（什么时候过期）

Secure字段是只在https的时候发送cookie

HttpOnly字段是浏览器无法通过document.cookie访问cookie

domain是允许访问该cookie的域名



## Cookie防篡改

Cookie是明文传输而且保存在客户端本地的，这就导致了Cookie很可能被篡改，假如客户端直接设置`Cookie`字段为`authed=true`并发送该HTTP请求，服务器就被欺骗了，所以Cookie还需要结合Session进行校验防止篡改

**通过给Cookie添加签名，使得服务器得以知道Cookie被篡改。**

1. 在服务器中配置一个不为人知的字符串（我们叫它Secret），比如： x$sfz32 。
2. 当服务器需要设置Cookie时（比如 authed=false ），不仅设置`authed`的值为`false`， 在值的后面进一步设置一个签名，最终设置的Cookie是 authed=false|6hTiBl7lVpd1P 。
3. 签名`6hTiBl7lVpd1P`是这样生成的： Hash('x$sfz32'+'false') 。 要设置的值与密钥相加再取哈希。
4. 用户收到HTTP响应并发现头字段 Set-Cookie: authed=false|6hTiBl7lVpd1P 。
5. 用户在发送HTTP请求时，篡改了`authed`值，设置头字段 Cookie: authed=true|??? 。 因为用户不知道密钥，无法生成hash签名，只能随便填一个。
6. 服务器收到HTTP请求，发现 Cookie: authed=true|??? 。服务器开始进行校验：Hash('true'+'x$sfz32') ，便会发现用户提供的签名不正确。判断cookie被篡改。

因为**Cookie是明文传输的**， 只要服务器设置过一次 `authed=true|xxxx `我不就知道`true`的签名是`xxxx`了么， 以后就可以用这个签名来欺骗服务器了。因此Cookie中最好不要放敏感数据。 一般来讲Cookie中只会放一个Session ID，而Session存储在服务器端。



## cookie的大小与条数限制

**一个网页cookie大小的限制为4kb左右，条数限制为20-50条左右**

## cookie的生命周期

一次会话的结束为关闭浏览器，关闭浏览器后就结束会话，默认情况下cookie的生命周期会一次会话，但可以通过expries属性设置cookie过期时间

## Cookie属性

path属性 设置cookie作用路径

domain属性 设置cookie作用域名

## Cookie的特点

Cookie 是存储在浏览器客户的一小片数据；
Cookie 可以同时被前台与后台操作；
Cookie 可以跨页面存取；
Cookie 是不可以跨服务器访问的；
Cookie 有限制； 每个浏览器存储的个数不能超过300个，每个服务器不能超过20个，数据量不能超过4K；
Cookie 是有生命周期的，默认与浏览器相同，如果进程退出，cookie会被销毁



# Session

Session是另一种记录客户状态（弥补HTTP无状态的缺憾）的机制，Session保存在服务端上，客户端访问服务端时，服务器把客户端信息记录在服务器上，当客户端再次访问时，对cookie中携带的SessionID进行校验。

当客户端首次访问服务端时，服务端上会生成Session ID与对应的Session，将SessionID和Session的对应关系保存进映射区。

当返回给客户端Cookie时，会将这个Session ID保存进Cookie中，客户端将Cookie保存起来，后续访问时Cookie会带上这个Session ID，然后服务端会进映射区中寻找这个状态进行比对

Session ID是经过一定哈希算法取得的，会按照浏览器的UA信息或者是客户端的IP地址来生成一个签名串，每次回去比对这个签名串与原来的session是否能匹配上，如果网络环境发生了变化，或者客户端发生变化，这个cookie都会无效。

## Session ID的保存方式

- 保存进cookie
- URL重写，当客户端禁止保存cookie，可以将Session ID放进URL
- 隐藏表单，服务器会自动修改表单，增加一个隐藏的字段，将Session ID保存进去

## Session失效时间

为了防止映射区内存溢出，服务器可以设置长时间未访问过的session会被删除。

也可以通过`HTTPSession.invalidate()`主动失效session

如果服务器服务进程终止，session也会失效

## session的缺点

如果一台服务器存储了session，如果做了负载均衡，假如负载均衡到B服务器，session就会失效



# Token

Token的定义：**Token是服务端生成的一串加密字符串**，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。

使用Token的目的：Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。

Token是服务端生成的根据客户端的userID进行加密的字符串，颁发给客户端用于验证身份，每次客户端发来token，服务端就根据同样的加密算法根据用户的userID再算一次，如果相同证明用户以前登陆过，可以直接登陆了

最简单的token组成:uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign(签名，由token的前几位以哈希算法压缩成一定长的十六进制字符串，可以防止恶意第三方拼接token请求服务器)。



## Token解决的问题

1. Token 完全由应用管理，所以它可以避开同源策略
2. Token 可以避免 CSRF 攻击(http://dwz.cn/7joLzx)
3. Token 可以是无状态的，可以在多个服务间共享



# 字符集和编码

计算机内的数据都是以二进制来保存的，为了让二进制转化为实际供人阅读的文件就需要用翻译的字符集和编码

**一套编码规范包括：字库表，字符集，编码方式**

字库表保存了实际的文字，类似GBK编码的字库表保存了几乎所有汉字

而字符集则保存了这些文字的在字库表中查找的二进制数地址，例如Ascll码A的编码为65，65的二进制就是A在字库表中的位置

编码方式是用于将一个较短的二进制数通过编码方式，转化为字符集中对应的二进制地址，再去字库表中找对应的字。编码方式用于节省空间。

## 常见编码规范

### Ascll

ASCII码一共规定了128个字符的编码，Ascall码只保存了英文和一些特殊字符，如空格等

### GBK

GBK编码保存了所有中日韩文字和英文，所有字都占2个字节

### Unicode

万国码，可以用32位二进制表示字，保存了世界上所有字，每个字符都需要4个字节，但是一些字不需要这么大的空间来表示，于是由在Unicode编码基础上设计了utf-8，utf-16，utf-32编码方式

## utf-8编码

utf-8不是一种编码规范，是针对Unicode的一种可变长度字符编码，它可以用来表示Unicode标准中的任何字符，而且其编码中的第一个字节仍与ASCII相容，使得原来处理ASCII字符的软件无须或只进行少部份修改后，便可继续使用。最多可以用四个字节32位二进制表示字符。

## 乱码

一串二进制字符数会使用一种编码方式变为一个字符，这个过程叫解码，一个字符通过一种编码方式转变为一串二进制数表示的过程叫编码。

解码的前提是字库表中有这个字符，乱码就是编码和解码所用的编码方式不一样。

## URL的"%编码"规范

URL采取ASCLL编码进行编码，如果URL中含有非ASCLL字符集中的字符，就需要对其进行编码。URL中一些保留字符，如“&”表示参数分隔符，如果需要在URL中使用也需要编码。

对URL中属于ASCLL字符集的非保留字不做编码，保留字取其ASCLL内码。然后加上“%”前缀将该字符进行编码，对URL中的非ASCLL字符需要取其Unicode内码，然后加上"%"前缀将该字符进行编码。

所以在URL中看到那么多%都是采用"%编码"的方式对URL中非ASCLL字符进行编码的字符。

所以HTTP中会携带上消息采取的编码方式



# HTTP协议身份认证

身份认证是确定用户身份的信息

常见认证方式

- BASIC认证（基本认证）
- DIGEST认证（摘要认证）
- SSL认证（客户端认证）
- FormBase认证（基于表单的认证）



## BASIC认证

BASIC认证使用质询/响应的方式

BASIC认证中用户名和密码都是明文传输的，如果被人窃听十分不安全

第一步：客户端发送请求

第二步：客户端请求的资源如果需要BASIC认证身份，客户端会返回状态码401告知客户端需要验证

第三步：客户端将用户名和密码已Base64的方编码式加入HTTP首部的Authorization字段

```
Authorization:Basic xxxxxxxxxx
后面的x就是经过Base64编码后的用户名和密码
```

第四步：如果认证成功返回状态码200，失败继续返回401



## DIGEST认证

为了弥补BASIC认证的弱点，从HTTP/1.1后有了DIGEST认证

DIGEST认证同样使用质询/响应的方式，但不会像BASIC认证那么发送明文密码

但DIGEST认证也不太安全，也不怎么使用了

第一步：客户端发送请求

第二步：客户端请求的资源如果需要DIGEST认证身份，客户端会返回状态码401告知客户端需要验证并返回一个临时的质询码（nonce），质询码是一段随机的字符串

第三步：客户端接收到质询码后，发摘要以及由质询码计算而来的响应码给服务端

```
Authorization:Digest username="xxx",realm="DIGEST",
nonce="xxxxxxx",url="xxxx",algorithm=MD5,response="xxxxxxxx"
// response是经过MD5计算的密码的响应码
```

第四步：如果认证成功返回状态码200，失败继续返回401



## SSL客户端认证

SSL客户端认证是借由HTTPS的客户端证书完成认证的方式，凭借客户端证书认证，服务器可确认访问是否来自已登录的客户端。也就是需要提前使用证书来认证身份，成本太高。



## 基于表单的认证

基于表单的认证方式并不是在HTTP协议中定义的，而是使用由web应用程序各自实现基于表单的认证方式。通过cookie和session的方式来保持用户状态



# HTTP/1.1长连接

HTTP基于响应/请求模式，因此只要服务端给了响应，本次HTTP请求就结束了。

HTTP的长连接与短连接本职上时TCP长连接与短连接。TCP连接是一个双向通道可以保持暂时不中断连接。

HTTP/1.0中默认使用短连接，浏览器和服务器每进行一次HTTP操作就建立一次连接，结束就中断

**HTTP/1.1起，默认使用长连接（keep-alive），用以保持连接特性，长连接的时间可以在中间件（如阿帕奇等）中设置**，但是HTTP/1.1的长连接还是有一些问题：pipeline ，虽然可以在一个TCP连接里发送多个HTTP请求，但是发送顺序和返回顺序必须一致，也就是后面的请求已经处理好了，前面的请求还没处理好，后面的处理结果也无法提前返回。HTTP/2.0二进制分帧修复了这个问题。

使用长连接可以一次传输诸多资源如js文件，图片，css文件等等

请求头设置字段，希望保持长连接（keep-alive）

```
'Connection': 'keep-alive'
```

响应头字段中允许长连接（默认）或者只允许短连接（close）

```
'Connection': 'keep-alive'  // HTTP/1.1默认长连接
'Connection': 'close'   // 可以手动设置为只能短连接
```



# 代理与网关

## HTTP中介代理

我们在客户端设置HTTP代理服务器，客户端所有HTTP请求就会先发送到HTTP代理服务器上，代理服务器自动提取请求数据包的Request数据，然后作为新客户端向web服务器发送请求，并且把web服务器返回的数据转发给发送请求的客户端，代理服务器是中间人，给服务器发送请求，并客户端发送响应

如果代理服务器不主动向服务端透露客户端的IP，并且不改变客户端发来的请求信息，那服务端完全察觉不到真实客户端的存在，这种类型的代理叫全匿名代理，除此之外，根据隐藏程度也可以分为匿名代理和透明代理

例如爬虫时通过多个代理服务器对目标服务器发送请求，这样防止单个ip访问频率过高被网站封杀

用户可以用HTTP代理服务器可以访问之前无法访问的资源，可以做缓存（加速访问资源），隐藏用户信息，客户端设置代理服务器这叫正向代理，而服务端使用的HTTP代理服务器叫反向代理

```
	客户端----------<代理>------------WEB服务器
			http			  http
```



## HTTP中介网关

网关是应用程序与资源之间的“协议转换器”

HTTP代理连接的是使用相同协议的客户端与服务端

网关代理的是使用不同协议的客户端与服务端，网关可以在一侧使用HTTP协议，另一侧使用另外一种协议

```
邮件服务器采用的不是http协议，是pop协议，可以使用网关来跟邮件服务器发送消息
	客户端----------<网关>------------email服务器
			http			  pop
```

同样网关可能存在客户端和服务器端任意一边

1.（HTTP/）服务器端网关：通过HTTP协议与客户端对象，通过其他协议与服务器通信

2.（/HTTP）客户端网关：通过其他协议与客户端对话，通过HTTP协议与服务器通信

常见网关类型

- （HTTP/*），类似用网关发邮件
- （HTTP/HTTPS）服务器端安全网关：客户端发来的HTTP请求在网关加密再发送给服务器，提高安全性
- （HTTPS/HTTP）客户端安全加速器网关：用户发来的HTTPS请求在网关就进行解密，发出HTTP响应就在网关加密为HTTPS，减轻服务器负荷
-    资源网关      客户端发送请求后，服务器并不回送响应而是通过网关api将请求发送给运行在服务器上的应用程序，然后应用程序将请求资源回送客户端，例如网络摄像头等





# HTTP缓存

有些网站第一次打开很慢，第二次就会快很多，就是因为有了HTTP缓存

HTTP缓存的内容主要是CSS，JS脚本，还有图片等更新频率不大的静态资源文件



浏览器在请求某一资源时，会先获取该资源缓存文件中响应头部携带的header信息，判断是否命中强缓存（cache-control和expires信息），若命中直接从缓存中获取资源信息，包括缓存header信息，本次请求就不会与服务器进行通信。

如果没有命中强缓存，浏览器会发送请求到服务器，请求会携带第一次返回的有关缓存的header字段信息（Last-Modifued/If-Modified-Since和Etag/If-None-Match四个协商缓存字段），如果命中协商缓存，服务器会返回新的协商缓存头部信息，浏览器直接使用协商缓存，如果没有命中则下载新资源



普通资源采用强缓存 + 协商缓存（Cache-Control字段+其他字段），既保证了时间不到不请求同一资源，又保证了时间到了如果资源没改缓存还能继续有效



如果一个资源还没到过期时间就可能会修改就采取纯协商缓存比如index.html文件

index.html文件采用协商缓存，理由就是要用户每次请求index.html不拿浏览器缓存，直接请求服务器，这样就保证资源更新了，用户能马上访问到新资源，如果服务端返回304，这时候再拿浏览器的缓存的index.html



## 强缓存（200）

浏览器缓存主要分为**强缓存**（也称**本地缓存**）和**协商缓存**（也称**弱缓存**）。

通常，**强缓存**不会向服务器发送请求，直接从缓存中读取资源，在chrome控制台的network选项中可以看到该请求返回200的状态码。每次用户正常打开这个页面，浏览器会判断缓存是否过期，没有过期就从缓存中读取数据。

强缓存字段为Cache-Control和Expires字段，它不到过期时间永远只使用缓存的数据，永远不会去服务器请求新数据



## 协商缓存（304）

**协商缓存**就是由服务器来确定缓存资源是否可用，所以客户端与服务器端要通过某种标识来进行通信，从而让服务器判断请求资源是否可以缓存访问。

协商缓存流程

发请求-->看资源是否过期-->过期-->请求服务器-->服务器对比资源是否真的过期-->没过期-->返回304状态码-->客户端用缓存的老资源。

发请求-->看资源是否过期-->过期-->请求服务器-->服务器对比资源是否真的过期-->过期-->返回200状态码-->客户端如第一次接收该资源一样，记下它的cache-control中的max-age、etag、last-modified等。

请求资源时，把用户本地该资源的 etag 同时带到服务端，服务端和最新资源做对比。
如果资源没更改，返回304，浏览器读取本地缓存。
如果资源有更改，返回200，返回最新的资源。

协商缓存就是每次使用缓存之前都会去服务器问一下，这个缓存是否还可用.





## 强缓存头部字段

### Cache-Control

请求/响应头，缓存控制字段

| 字段                                 |                                                              |
| :----------------------------------- | ------------------------------------------------------------ |
| public                               | 所有内容都将被缓存(客户端和代理服务器CDN都可缓存)            |
| private                              | 内容只缓存到私有缓存中(仅客户端可以缓存，代理服务器CDN不可缓存) |
| no-cache                             | 跳过设置强缓存，但是不妨碍设置协商缓存；一般如果做了强缓存就不会发起请求了，只有在强缓存失效了才走协商缓存的。但设置了no-cache即使强缓存没过期依然会发送请求询问服务端判断缓存是否过期（根据协商缓存信息）。 |
| no-store                             | 所有内容都不会被缓存（包括强缓存协商缓存）                   |
| must-revalidation/proxy-revalidation | 如果缓存的内容失效，请求必须发送到服务器/代理以进行重新验证  |
| max-age=xxx                          | 缓存的内容将在 xxx 秒后失效, 这个选项只在HTTP 1.1可用, 并如果和Expires和Last-Modified一起使用时, 优先级比这两者高 |
| s-maxage = xxx                       | 只能设置public缓存设备（例如CDN）的过期时间，优先级高于max-age |

```javascript
res.writeHead(200, {
  'Content-Type': 'text/html;charset=utf-8',
  'Cache-Control': 'private, max-age=20, no-cache'
})
```



### Expires

响应头字段Expires，代表资源过期时间，由服务器返回提供，比Cache-Control字段的max-age优先级低





## 协商缓存头部字段

### Last -Modified

响应头属性，资源最新修改时间，由服务器告诉浏览器

### if-Modified-Since

请求头属性，资源最新修改时间，由浏览器告诉服务器，也就是上次请求返回的Last -Modified





### Etag

HTTP/1.1新增的响应头字段

每个文件有一个，改动文件了就变了，就是个文件hash，每个文件唯一，有些时候文件修改时间改了，但内容没改，可以通过Etag对比，Etag和Last -Modified优先级可以由服务端进行设置。

### if-None-Match

请求头属性，缓存资源表示，由浏览器告诉服务器，就是上次服务器发送过来的Etag





```javascript
res.writeHead(200, {
  'Content-Type': 'text/html;charset=utf-8',
  'Cache-Control': 'max-age=20, no-cache',
  'Last -Modified': '123',
  'Etag': '456'
})
```





## HTTP缓存工作方式

服务器发送给浏览器一个文件，并在HTTP响应里添加了**响应头字段Expires**，Expires规定了这个资源的资源过期时间，后续请求这个文件，会先对比Expires时间，如果时间没过就会去缓存直接加载这个文件

但是可能过了过期时间，但是这个文件在服务器也没有被修改，就没必要重新加载这个文件，所以就有了文件最新修改时间对比的字段**响应头字段Last -Modified**和**请求头字段if-Modified-Since**。

服务器将**文件+Expires+Last -Modified**一起返回给浏览器，如果Expires过期，就将上次请求文件返回的响应头字段**Last -Modified**在请求头中设置为字段**if-Modified-Since**，服务器接收到后会去和服务器上的**Last -Modified**对比，如果不相等就会返回**新文件+新Expires+新Last -Modified**，如果相等，返回状态码304，告诉浏览器该文件并未修改直接在缓存中使用。

但是请求头字段**if-Modified-Since**由客户端掌握容易被修改，而且响应头字段**Expires**最大时间只能精确到秒，所以就有了加强的方法，服务端首次发送文件的时候再加上一个响应头字段Etag，并且用**缓存头部字段Cache-Control字段的max-age属性**来代替Expires字段。此时服务器端发送**文件+max-age+Last -Modified+Etag**，下次客户端请求这个文件的时候，在HTTP请求头部加入**if-Modified-Since字段**和**if-None-Match字段（也就是上次发送过来的Etag字段）**，服务器会将请求的**if-None-Match**字段与服务器上Etag对比，如果相等，返回状态码304，告诉浏览器该文件并未修改直接在缓存中使用，不等则返回**新文件+新max-age+新Last -Modified+新Etag**



# 缓存改进方案

## md5/hash缓存

通过不缓存html，为静态文件添加MD5或者hash表示，解决浏览器无法跳过缓存过期时间主动感知文件变化的问题，原本资源下载缓存在浏览器后，在服务器端源文件不能修改名字修改位置，而通过添加md5/hash缓存能解决这个问题



## CDN缓存

CDN是构建在网络上的内容分发网络，依靠部署在各地的边缘服务器（网络运营商机房），通过中心平台的负载均衡，内容分发，调度等功能模块，让用户能就近获取资源，降低网络阻塞，提供用户访问与响应速度和命中率。

CDN是服务器和浏览器之间的转发站，一些热门资源都放在各自转发站里，分流降低中心服务器压力，加快用户访问速度。

服务器第一次收到请求后，会通知浏览器去找CDN缓存，从CDN下载后浏览器自己也会进行缓存

后续请求时，对比文件会直接到CDN节点对比缓存文件，CDN节点会代替服务器对比文件，如果没有过期，则浏览器访问自己的缓存，如果过期，CDN节点会去服务器请求新文件，然后再分发给浏览器。



# 浏览器的操作对HTTP缓存的影响

| 用户操作     | 强缓存                 | Last-Modified/Etag     |
| :----------- | ---------------------- | ---------------------- |
| 地址栏回车   | 缓存有效               | 缓存有效               |
| 页面链接跳转 | 缓存有效               | 缓存有效               |
| 新开窗口     | 缓存有效               | 缓存有效               |
| 前进后退     | 缓存有效               | 缓存有效               |
| F5刷新       | 缓存强制无效，重新下载 | 缓存有效               |
| Ctrl+F5      | 缓存强制无效，重新下载 | 缓存强制无效，重新下载 |





# 内容协商机制

一个URL可能携带不同的资源，比如google有英文中文等版本，但我们直接进入网站他就自动显示合适的语言，这就是内容协商机制，使得单一的URL携带了不同的资源，客户端和服务端就响应的资源内容进行交涉，然后提供给客户端最合适的资源，内容协商会以响应资源的语言，字符集，编码方式等作为判断的基准。

## 内容协商方式

- 客户端驱动

  客户端发起请求，服务器发送可选项列表，客户端做出选择后发送第二次请求

- 服务器驱动

  服务器检查客户端的请求头部集并决定提供哪个版本的页面

- 透明协商：某个中间设备（通常是缓存代理）代表客户端进行协商，极为少用



## 服务器驱动内容协商

**请求头部集**

请求头中的某些字段可以跟服务器进行内容协商

- Accpt : 告诉服务器发送何种媒体类型
- Accpt-Charset  ： 告诉服务器发送何种字符集
- Accpt-Langeuage  :  告诉服务器发送何种语言
- Accept-Encoding  ： 告诉服务器采用何种编码

- User-Agent：告诉服务器当前浏览器的属性

**响应头部集**

告诉客户端服务器回应了哪些内容，已上面一一对应

- Content-Type对应Accpt
- Content-Language
- Content-Encoding



### 近似匹配

```
Accept-Language: en;q=0.5,fr;q=0.0,nl;q=1.0,tr;q=0.0
```

q值代表属性值优先级，nl为荷兰语，优先级最高，en为英文，优先级次之，fr，tr优先级为0





# 内容安全策略CSP

```
Content-Security-Policy
```

这个http字段限制资源的获取并报告资源获取越权，可以通过default-src属性限制所有跟超链接有关的资源的访问。

资源类型有：

connect-src    请求发送的地址链接

img-src

style-src

font-src

script-src

...



所有外链加载的资源都可以使用这个响应头字段进行限制

```javascript
res.writeHead(200, {
  'Content-Type': 'text/html;charset=utf-8',
  'Content-Security-Policy': 'defaule-src http: https:'  // 限制外链只能通过http/https来访问
})
```





# 断点续传和多线程下载

HTTP请求头字段Range和响应头字段Content-Range来支持断点续传，断点续传应用在，比如下载一个资源是突然网络中断了，客户端是需要重新下载还是可以请求续传

## Range

Range用于请求头中，指定第一个字节的位置到最后一个字节的位置

```
Range:bytes=0-499
从0字节开始到499字节这段数据

Range:bytes=-500
最后五百字节内容

Range:bytes=500-
从第五百字节到文件结束的内容

Range:bytes=500-600,601-999
即从500-600下载，又从601-999下载，一起下载
```

## Content-Range

在响应头中，在发出带有Range的请求后，服务器会在Content-Range头部返回当前接受的范围和文件总大小

告诉是否下载成功了想要的区间，和文件总大小

512000-为成功下载的区间，1024000为文件总大小

```
Content-Range:bytes 512000-/1024000
```

而且在下载完成后，服务器发送的状态码也不同

不使用断点续传方式返回  HTTP/1.1 200 OK

使用断点续传方式返回	  HTTP/1.1 206 Partial Content

## 断点续传过程

1. 客户端下载一个1024k的文件，已经下载了512k

2. 网络中断，客户端请求续传，因此需要在HTTP请求头中申明本次需要续传的片段：Range:bytes=512000-

3. 服务端接收到断点续传请求，从文件512k位置开始传输，并且在HTTP响应头中添加

   ```
   Content-Range:bytes 512000-/1024000
   ```

   并且此时服务端返回的HTTP状态码变为206而不是200





# HTTPS

HTTP的传输是完全以明文的方式进行，不做任何加密，安全性很差，中间人通过截获数据包可以获知或者篡改信息，这叫中间人攻击。

HTTPS是为了解决HTTP传输加密安全性提出的协议，HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。**简言之， 所谓HTTPS， 其实就是身披SSL协议这层外壳的 HTTP。在采用 SSL后， HTTP 就拥有了 HTTPS 的加密、 证书和完整性保护这些功能。**

传统的HTTP协议通信：传统的HTTP报文是直接将报文信息传输到TCP然后TCP再通过TCP套接字发送给目的主机上。

HTTPS协议通信：HTTPS是HTTP报文直接将报文信息传输给SSL套接字进行加密，SSL加密后将加密后的报文发送给TCP套接字，然后TCP套接字再将加密后的报文发送给目的主机，目的主机将通过TCP套接字获取加密后的报文给SSL套接字，SSL解密后交给对应进程。



## HTTPS协议概述

HTTPS可以认为是HTTP协议+TLS协议，TLS传输协议是HTTPS安全的基本。

TLS是传输层加密协议，它的前身是SSL协议，两个协议是一个东西，TLS可以认为是建立在传输层和应用层之间。

- 内容加密
  - 非对称密钥加密
  - 对称内容加密
- 身份认证（证书）
  - 数字证书
- 数据完整性



## 非对称加密

对明文进行加密分为对称加密和非对称加密，**加密和解密使用同一个密钥（唯一密钥）叫 对称加密**，如果第一次通信时密钥被截获，信息也会被获取，相当于两个人公用加解密的方法（唯一密钥），第一次发送加解密方法的时候被截获，后面信息就完全被获取了



**不使用一套密钥进行加密解密叫非对称加密，服务端和客户端各自有公钥密钥**

1.A要向B发送信息，A和B都要产生一对用于加密和解密的公钥和私钥

2.A的私钥保密，A的公钥告诉B；B的私钥保密，B的公钥告诉A。

3.A要给B发送信息时，A用B的公钥加密信息，因为A知道B的公钥。

4.A将这个消息发给B（已经用B的公钥加密消息）。

5.B收到这个消息后，B用自己的私钥解密A的消息。其他所有收到这个报文的人都无法解密，因为只有B才有B的私钥



相当于每个人都有一把锁和一把钥匙，通信双方先交换锁，但钥匙只有自己有，所以对方发送的信息上了自己的锁以后只有自己能打开

但非对称加密也会被中间人攻击，因为在交换公钥（交换锁）的时候（第二步），中间人会偷偷把公钥换成自己的公钥，这样信息又被截获了（相当于在交换锁的时候偷偷把锁给换了）。

并且一直使用非对称加密太耗费时间了，还是需要对称加密才能稳定高效的传输内容，HTTPS提出了**安全的利用 非对称加密 交换 对称加密 的唯一密钥**

HTTPS分为验证证书阶段（非对称加密）和内容传输阶段（对称加密）



**验证证书阶段**

**HTTPS的思想引入了一个权威第三方：证书机构(CA)**

服务端向证书机构发送自己的公钥，**证书机构会根据服务端的公钥和网址生成规则等生成该网址唯一的证书签名**，证书签名经过证书机构的私钥加密，机构把证书发送给服务端

用户向服务端发送请求时，服务端不再直接返回给客户端自己的公钥了，而是把自己的证书返回给了客户端，客户端拿到证书第一件事就是验证证书真伪，**浏览器和操作系统内置了权威机构的名称和公钥**，客户端找到对应的机构公钥解密服务端的证书签名得到服务端的公钥，解密后客户端根据跟证书机构同样的规则（解密规则浏览器和操作系统内置）自己生成一个证书签名，对比两个证书，如果两个证书签名一模一样则证明不是中间人发送的假证书（不是中间人发送的假公钥），**解密出来的公钥就是服务器的公钥**。

接下来浏览器随机生成，用于之后对称加密的唯一密钥，并用服务端公钥加密后发送给服务端，服务端拿到后用自己密钥进行解密后得到了本次对称加密的唯一密钥，这样就做到了安全的交换密钥，不怕公钥被中间人偷偷换掉，这样就完成了对双方身份的验证。之后就可以根据这个唯一密钥进行对称加密传输内容了



**内容传输阶段**

验证证书阶段为非对称加密，**HTTPS 在内容传输的加密上却还是使用的是对称加密**

因为非对称加密，加解密阶段是非常消耗时间的

- 1）当证书验证合法后，在本地生成随机数（对称加密唯一密钥）；
- 2）通过服务端公钥加密随机数，并把加密后的随机数传输到服务端；
- 3）服务端通过私钥对随机数进行解密；
- 4）服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输。
- 5）服务端根据唯一密钥进行解密获取内容





## SSL/TLS

SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。以及检验客户端和服务端是否安全。TLS与SSL在传输层对网络连接进行加密。

SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。
**SSL介于应用层和传输层（TCP）之间**。应用层数据不再直接传递给传输层，而是传递给SSL层，SSL层对从应用层收到的数据进行加密，并增加自己的SSL头。

HTTP协议：HTTP(应用层)---TCP(传输层)---IP(网络层)---网络接口（数据链路层）

HTTPs协议：HTTP(应用层)---SSL/TLS（安全层）---TCP(传输层)---IP(网络层)---网络接口（数据链路层）



## SSL四次握手

SSL需要经历四次握手

一、客户端发出加密通信请求ClientHello

提供： 
1，协议版本（如TSL1.0） 
2，随机数1（用于生成对话密钥） 
3，支持的加密方法（如RSA公钥加密） 
4，支持的压缩方法



二、服务器回应SeverHello

回应内容： 
1，确认使用的加密通信协议版本（TSL1.0） 
2，随机数2（用于生成对话密钥） 
3，确认加密方法（RSA） 
4，服务器证书（包含非对称加密的公钥） 
5，（可选）要求客户端提供证书的请求



此时客户端开始验证证书

如果证书不是可信机构颁布，或证书域名与实际域名不符，或者证书已经过期，就会向访问者显示一个警告，是否继续通信



三、客户端回应

验证证书没有问题后，就会取出证书中的服务器公钥 
然后发送： 
1，随机数3（pre-master key，此随机数用服务器公钥加密，防止被窃听） 
2，编码改变通知（表示随后的信息都将用双方商定的方法和密钥发送） 
3，客户端握手结束通知



此时双方生成会话密钥

双方同时有了三个随机数，接着就用事先商定的加密方法，各自生成同一把“会话密钥” 
服务器端用自己的私钥（非对称加密的）获取第三个随机数，会计算生成本次所用的会话密钥（对称加密的密钥），如果前一步要求客户端证书，会在这一步验证



四、服务器最后响应

服务器生成会话密钥后，向客户端发送： 
1，编码改变通知（后面的信息都用双方的加密方法和密钥来发送） 
2，服务器握手结束通知

至此，握手阶段全部结束，接下来客户端与服务器进入加密通信， **SSL连接完成后，建立TCP连接，发送HTTP请求**， SSL连接建立完成，通信会受到 SSL的保护。 从此处开始进行应用层协议的通信， 即发送 HTTP 请求。



## HTTPS使用成本

- 证书费用以及更新维护
- HTTPS降低访问速度
- 内容对称加解密消耗CPU资源，服务端需要大量资源



## HTTPS对性能的影响

- 协议交互所增加的RTT（往返时延）

  因为用户不会输出https完整网址，所以到原本的http网址后，服务器会返回302让浏览器重定向到https网址，因为https的端口和原本http不同，所以需要重新TCP三次握手建立连接，然后会进入TLS四次握手阶段，中间会经历多次往返，产生很多RTT

- 加解密相关的计算耗时

  - 浏览器计算耗时
  - 服务端计算耗时





# HTTP1.0/1.1的瓶颈

HTTP的优点是简单便捷

可能影响HTTP网络请求的因素

- 带宽
- 延迟
  - 浏览器的阻塞
  - DNS解析延迟
  - 一条连接上只可发送一个请求，HTTP/1.1后keep-alive可以保持连接但会增加服务器压力	

HTTP/1.1 比HTTP/1.0增加了缓存，断点续传（Range），长连接等优点，但也有一些缺点：

HTTP/1.1在每次传输数据的时候每次都需要重新建立连接，增加了大量延迟时间

HTTP/1.1传输的时候也是明文传输，容易被窃取

HTTP/1.1传输时允许同时开启多个TCP连接传输数据，使客户端和服务器可以一次建立多条连接发送消息，但是头部携带了大量的信息，但每次请求/响应头部都不怎么变化，虚耗了很多带宽，并且虽然有keep-alive帮助解决问题但会增加很多不必要的连接给服务端增加很大的压力，并且存在pipeline（必须按请求的顺序返回）的问题



**总结1.0/1.1的瓶颈主要有以下几点**

- 一条连接只能发送一个请求，开启长连接后消耗性能，且必须按请求的顺序进行返回

- 请求只能从客户端开始，客户端不可以接收除了响应以外的指令，服务端不能主动推送消息
- 请求/响应头部不经压缩就发送
- 每次互相发送相同头部造成浪费较多
- 非强制压缩发送消息





# HTTP/2.0

为了解决HTTP/1.0的瓶颈，推出了HTTP/2.0，使用HTTP/2.0可以在中间件（例如nginx）中快速配置。在HTTPS开启的情况下才能使用HTTP/2.0。

## 二进制分帧

HTTP2.0性能增强核心是**二进制分帧**，实现了低延迟和高吞吐量。

并且二进制分帧解决了HTTP/1.1长连接pipeline的问题 ，HTTP/1.1长连接虽然可以在一个TCP连接里发送多个HTTP请求，但是发送顺序和返回顺序必须一致，也就是后面的请求已经处理好了，前面的请求还没处理好，后面的处理结果也无法提前返回。

二进制分帧层时在应用层（HTTP/2.0）和传输层（TCP）之间新增的层，在二进制分帧层，HTTP/2.0会将传输的信息转换为更小的消息和帧，并采取二进制编码，一条HTTP消息的消息头被封装到HEADERS帧，消息体会被封装到DATA帧，然后HTTP/2.0的通信可以都在一个连接上完成，这个连接可以承载任意数量的双向消息流，每个数据流都以消息的方式发送，而消息由一个帧或者多个帧组成，这些帧可以乱序发送，然后根据每个帧首部的流标识符重新组装。

HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP / 1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。

**HTTP/2 中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。**每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。



**帧：**HTTP/2 数据通信的最小单位消息：指 HTTP/2 中逻辑上的 HTTP 消息，例如请求和响应等。消息由一个或多个帧组成。

**流stream：**存在于连接中的一个虚拟通道。流可以承载双向消息，每个流都有一个唯一的整数ID。将应用层的数据经过二进制帧层处理，将不同的请求拆成不同的stream，由stream的id进行标记，请求的stream被分割成多种类型的帧，其中包括head帧和data数据帧。正是因为有了stream的id标记、以及各种不同类型的帧，确保了请求和响应的有序重组。在TCP层，可能会进一步对这些数据进行拆分，拆成不同报文序号进行传输，但是可以无需关注这层是如何拆分、组装的。因为可以在Http2.0的二进制帧层进行有序处理，将接收到的stream的id为1的放一起处理，接收到的stream的id为2的放一起处理。通过这种方式就可以解决Http1.1中存在的请求阻塞问题，试想：假如a.js的处理很慢，服务器可以先将b.css的处理结果返回，因为采用了stream的id编号，所以可以在Http2.0的二进制帧层先对b.css的stream的id进行重组，将b.css的响应交付于应用层处理。




## 首部压缩

HTTP/2.0为了防止HEADER帧过大，采取了**首部压缩**的方式解决HTTP/1.0首部过大的问题，首部很多信息相同，每次请求却需要完整的带上。

HTTP/2.0使用了一个叫首部表的东西跟踪和存储之前发送的HEADER帧键值对，相同的首部信息不再原封不动的发送，下次消息发送HEADERS帧只发送变化的首部信息，不变的首部信息被加到首部表里，首部表在HTTP/2.0连接期内持续存在，由客户端和服务端共同更新和拥有。



## 信道复用

多路复用，代替原来的序列和阻塞机制。所有就是请求的都是通过一个 TCP连接并发完成。 HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制，超过了这个数量就需要等待。

HTTP/2.0所有通信都在一条连接上完成，通信的最小单位变为了一个个的帧，在一个TCP连接上双向交换信息

利用了现在普遍的高带宽，使低延迟的需求得到了实现

这种单链接多资源的方式好处有

- 减少服务端保持多条链接的压力，内存占用少，连接吞吐量大
- 由于TCP连接减少而使网络阻塞状况得以改观
- 慢启动时间减少，拥塞和丢包恢复速度更快
- 同域名下所有通信都在单个连接上完成。
- 单个连接可以承载任意数量的双向数据流。
- 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。

由于HTTP/2.0的这些优势，所以使雪碧图，js合并css文件这些以往的HTTP/1.0的优化手段变得没那么大用处了



## 并行双向字节流的请求和响应

HTTP/2.0上客户端和服务器可以把HTTP消息分解成互不依赖的帧，然后乱序发送，最后由接收方根据每个帧首部的流标识符组装，同一个连接上有多个不同方向的消息流在传输。并且HTTP/2.0服务器可以针对一个请求发送多个响应。

- 并行交错的发送请求，请求直接互不影响
- 并行交错的发送响应，响应直接互不影响
- 只需要一个连接即可并行发送多个请求和响应
- 消除不必要的延迟减少页面加载时间



## 请求优先级

因为发送消息和响应都没有先后顺序，为了让重要的消息先发送，HTTP/2.0设置了请求优先级。每个请求都可以带一个31bit的优先值，0表示最高优先级， 数值越大优先级越低。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。

- 高优先级的流应该优先发送
- 但优先级不是绝对的，不同优先级混合也是必须的，防止饥饿



## 服务器推送

服务端可以在发送页面HTML时主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。

服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送RST_STREAM帧来拒收。主动推送也遵守同源策略，服务器不会随便推送第三方资源给客户端。





## HTTP/2.0的瓶颈

- **队头阻塞**，如果HTTP/2.0出现丢包的情况，整个TCP都要等待重传，所有数据都被阻塞住了，HTTP/1.0我们都是开启多条TCP连接传输数据，一条阻塞了不严重，但HTTP/2.0所有数据都是在一条TCP连接上完成的，一旦有一个包丢包阻塞了，TCP为了保证消息可靠性需要重传这个包，所有消息即使到达了接收端也会被阻塞在接收端，等待重传才能被读取。
- 建立连接的握手延迟大，HTTPS和HTTP/2.0除了TCP连接外还需要TLS进行安全传输，导致了需要TCP三次握手，TLS完全握手会增加多个RTT（往返时延），导致握手延迟大



# HTTP/3.0（QUIC协议）

谷歌推出改进HTTP2.0的协议----QUIC协议

- 采取UDP代替TCP连接
- 没有队头阻塞的多路复用



# WebSocket

HTTP/1.0的生命周期为一次Request和Response，HTTP/1.1加入了keep-alive使一次TCP连接可以发送多次HTTP请求，但是一次Request只能有一条Response，Response永远是被动发送的。WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。

WebSocket 协议是应用层协议，和http，ssl在同一层级，本质上是一个基于 TCP （TCP在传输层）的协议。也就是 WebSocket依然需要TCP来传输信息。

 **WebSocket是一个兼容HTTP握手规范的协议，WebSocket可以看做是HTTP为了支持长连接而重新设计的协议，是一种解决HTTP瓶颈的改进。**WebSocket并不是全部基于HTTP协议，因为现代互联网基于HTTP，所以WebSocket在设计之初兼容了HTTP。WebSocket现存大量的HTTP基础设施，代理，过滤，身份认证等等，WebSocket借用HTTP和HTTPS的端口。

由于使用HTTP的端口，因此TCP连接建立后的握手消息是基于HTTP的，由服务器判断这是一个HTTP协议，还是WebSocket协议。 WebSocket连接除了建立和关闭时的握手，数据传输和HTTP没丁点关系了。

WebSocket允许服务端主动向客户端推送数据。**在 WebSocket API 中，浏览器和服务器只需要完成一次握手**，然后，浏览器和服务器之间就形成了一条快速通道，两者之间就直接可以创建持久性的连接，并进行双向数据传输，并且这个连接会持续存在直到客户端或者服务器端的某一方主动的关闭连。



WebSocket协议第一步是客户端发送一条HTTP请求告知服务端，浏览器请求升级到WebSocket 协议

服务端回复一条HTTP响应告知支持WebSocket协议，以后发送消息使用WebSocket协议

```
//一个客户端发送的WebSocket请求
GET / HTTP/1.1
Upgrade: websocket      //Upgrade和Connection字段提醒服务器，表示客户端希望连接升级WebSocket协议
Connection: Upgrade		
Host: example.com
Origin: http://example.com
Sec-WebSocket-Version: 13			//WebSocket协议版本
Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ==    
//Base64随机加密串，验证是否能支持WebSocket，要求服务端必须返回一个对应加密的Sec-WebSocket-Accept应答，否则客户端会抛出Error during WebSocket handshake错误，并关闭连接。

```

```
//一个服务端发送的响应
HTTP/1.1 101 Switching Protocols
Upgrade: websocket		//Upgrade和Connection字段提醒客户端，同意升级为WebSocket协议
Connection: Upgrade
Sec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=   //解请求的Base64随机加密串
Sec-WebSocket-Location: ws://example.com/
```



WebSocket是类似Socket的TCP长连接通讯模式。一旦WebSocket连接建立后，后续数据都以帧序列的形式传输。在客户端断开WebSocket连接或Server端中断连接前，不需要客户端和服务端重新发起连接请求。在海量并发及客户端与服务器交互负载流量大的情况下，极大的节省了网络带宽资源的消耗，有明显的性能优势，且客户端发送和接受消息是在同一个持久连接上发起，实时性优势明显。

WebSocket 可能进入某种半死不活的状态。这实际上也是原有网络世界的一些缺陷性设计。上面所说的 WebSocket 真.长连接虽然解决了服务器和客户端两边的问题，但坑爹的是网络应用除了服务器和客户端之外，另一个巨大的存在是中间的网络链路。一个 HTTP/WebSocket 连接往往要经过无数的路由，防火墙。你以为你的数据是在一个“连接”中发送的，实际上它要跨越千山万水，经过无数次转发，过滤，才能最终抵达终点。在这过程中，中间节点的处理方法很可能会让你意想不到。

比如说，这些坑爹的中间节点可能会认为一份连接在一段时间内没有数据发送就等于失效，它们会自作主张的切断这些连接。在这种情况下，不论服务器还是客户端都不会收到任何提示，它们只会一厢情愿的以为彼此间的红线还在，徒劳地一边又一边地发送抵达不了彼岸的信息。而计算机网络协议栈的实现中又会有一层套一层的缓存，除非填满这些缓存，你的程序根本不会发现任何错误。这样，本来一个美好的 WebSocket 长连接，就可能在毫不知情的情况下进入了半死不活状态。

而解决方案，WebSocket 的设计者们也早已想过。就是让服务器和客户端能够发送 Ping/Pong Frame，这种 Frame 是一种特殊的数据包，它只包含一些元数据而不需要真正的 Data Payload，可以在不影响 Application 的情况下维持住中间网络的连接状态。



## HTTP轮询方式

HTTP轮询都具有一些缺点，比如需要服务器有很快的响应速度或者需要高并发。并且服务端永远只能被动的响应客户端发送的消息无法主动发送。

### AJAX轮询

让浏览器每过一段时间就发送请求问服务器是否有新消息可以请求，服务端收到请求如果没有新消息需要给浏览器一个没有新消息的响应，浏览器过一段时间后又发送请求问服务器是否有新消息可以请求，如此循环叫AJAX轮询。

AJAX轮询需要服务器有很高的响应速度



### Long Poll (长轮询)

浏览器向服务器询问一次是否有新消息可以请求，但是服务端如果没有新消息就阻塞等待新消息产生，不发送响应，客户端也阻塞等待，有新消息时，服务端再向浏览器发送消息，如此循环叫长轮询。

长轮询需要服务器有很大的并发



## WebSocket轮询方式

WebSocket协议第一步是客户端发送一条HTTP请求告知服务端，浏览器请求升级到WebSocket 协议，之后服务端回复一条HTTP响应告知支持WebSocket协议，以后发送消息使用WebSocket协议。

以后如果服务端有消息了，可以主动推送给客户端，这样的协议解决了HTTP轮询的缺点，这样的设计叫回调。

WebSocket协议中，只需要一次HTTP消息升级协议之后服务端会跟客户端建立持久的连接并且能主动发送消息。

- WebSocket是真正的全双工方式
- 减少了通信量

WebSocket使得客户端与服务端的信息交换变得更加简洁了，运行服务端主动发送消息，在WebSocket api中浏览器和服务器只需要一次HTTP握手就能建立连接并进行双向双工数据传输







# Web安全

## web应用三层架构

Web表示层（前端）

业务逻辑层（后端）

数据层（数据库）

Web安全问题主要出现在前端和后端之间的传输环节

## 六大web安全威胁

- 验证
- 授权
- 客户端攻击
- 命令执行
- 信息暴露
- 逻辑性攻击

## 漏洞分类

- 注入类
- 失效的身份认证
- 敏感信息泄露
- XML外部实体
- 失效的访问控制
- 安全配置错误
- xss跨站脚本
- 不安全的反序列化
- 使用含有已知漏洞的组件
- 不足的日志记录和监控





# 验证机制漏洞

验证机制是web应用中最简单的一种安全机制，比如密码，验证机制是防止恶意攻击的核心机制

## 典型身份验证模式

1 用户登录

2 服务端生成session并写入cookie传回客户端

3 下次登录通过cookie中的sessionID验证身份

## 验证技术

- 基于HTML表单的验证

- 实体SSL证书

## 漏洞

- 弱密码

- 暴力破解密码

  ​	通过在cookie上设置尝试登录次数来解决

  ​	

# 会话管理

会话管理机制是一个基本的安全组件

它可以在用户通过请求提交证书以后持续向应用程序保证用户身份的真实性





# SQL注入

web应用用户经常提交更新数据的SQL语句

但是如果建立SQL语句的方法不安全，就很容易收到SQL注入的攻击

比如在用户名用户密码输入框输入了一条SQL语句，如果没做防御，可能对数据库产生危害

- 探至数据库的具体结果，为进一步攻击做准备
- 泄漏数据

- 取得更高权限，来修改表数据甚至是内部数据



## SQL注入防御

参数化查询，参数化查询是对SQL注入根本性的防御策略，也叫做预处理语句，在建立一个包含用户输入的SQL语句时分为两步：

1.指定查询结构,用户输入预留占位符 

2.指定占位符内容



node中可以使用mysql模块提供的escape函数对用户输入的字符串进行处理

```javascript
const mysql = require('mysql')
const login = (username, password) => {
    // 对接收到的username和password用escape函数进行处理
    username = mysql.escape(username)
    password = mysql.escape(password)
    /*
    原本sql语句为
    const sql = `
	select username from users where username='${username}' and password='${password}'
	`
	使用escape函数后会去掉单引号
    */
    const sql = `
	select username from users where username=${username} and password=${password}
	`
    ... // sql语句查询
}
```

escape函数原理是将可能影响sql执行的字符串进行转义和去除

sql中--为注释符号

例如用户输入`zhangsan';--`，单引号会打断前一个单引号导致`--`被sql语句识别，后面的password被注释。经过函数处理后变为`zhangsan\'--`，转义单引号不会打断sql语句







# XSS攻击原理

跨站脚本攻击，XSS是一种经常在web应用中出现的计算机安全漏洞，它允许恶意web用户将js代码植入到提供给其他用户使用的页面中，其他用户观看网页时，恶意脚本就会执行。

例如做一个钓鱼网站，然后注入一个js脚本（并和服务器解决跨域问题）恶意获取当前用户的cookie信息，随后用户的cookie信息就会被盗取

例如在编辑博客title写入一段`<script>alert{document.cookie}</script>`，这样点击上传后端数据库的title就是一段js代码，前端再从数据库中获取时，获取到的title就是这段代码，就会把cookie弹出来

**XSS攻击原理**

- 注入HTML/JS等危害脚本发起攻击
- 攻击成功后，攻击者就可以获得私密的网页内容和cookie等

**XSS攻击危害**

- 盗取用户账户密码
- 控制数据
- 盗取用户电脑资料

**XSS攻击分类**

- 反射式XSS
- 存储式XSS
- 基于DOM的XSS

## 反射式XSS

也称为非永久性XSS，是目前最流行的XSS攻击

它出现在服务器直接使用客户点提交的数据，如URL的数据，html表单中提交数据，并且没有对数据进行无害化处理，如果提交的数据中含有HTML控制字符而没有被正确处理，那么一个简单的XSS攻击就会发生

反射式攻击可能是垃圾邮件内一个钓鱼网站的网址链接，链接可能存有XSS攻击脚本，点开浏览器可能就会执行这种脚本



## 存储式XSS

也称为永久性XSS

这种攻击将脚本上传到Web服务器上，使得所有访问该页面的用户都面临信息泄露的问题，Web服务管理员也可能中招。

比如向网站管理员发送一段含有恶意脚本代码的私信，共享的文件等等，都可能出现存储式XSS

比如攻击者发布一个热点信息，点击的用户都会被攻击者获取到cookie和其他信息



## 基于DOM的XSS攻击

反射式XSS攻击和存储式XSS攻击都是**通过服务器端提取用户提交的数据**并且以不安全的方式返回给用户。

基于DOM的攻击仅仅通过javascript的方式执行

这种攻击常发生在应用程序每次返回相同的静态HTML，而通过客户端javascript动态生成信息，并不会跟服务端交互的时候。

**XSS攻击载荷**

载荷是可能被攻击的地方

- 会话令牌，控制一个用户的会话令牌，用用户的身份访问网站，执行恶意操作
- 虚拟置换，在一个web网站注入恶意数据，从而向应用程序的用户传达错误的信息，比如向站点注入html，让用户跳转到设置的钓鱼网站上，攻击者实际上没有修改服务端的内容，反而是利用被下载到用户客户端上的js脚本恶意修改了用户访问时的页面展示，让用户跳转到钓鱼网站上
- 注入木马



## XSS防御措施

- 输入确认和输出净化

1. 输入验证

2. 输出编码

   将恶意脚本和恶意html语句以html编码的形式进行编码转译，例如将` < `转码成`&lt;`，`>`转码为`&gt;`，如果变成了编码就会被当做html文档内容的一部分，例如`<script>`就会变为`&lt;script&gt;`，前端识别时再做转义即可

可以使用xss插件进行快速转义

```
npm i xss --save
```

```javascript
const xss = require('xss')
...
const title = xss(blogData.title)
```

- 给cookie设置httponly

  在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击



# CSRF攻击原理

跨站请求伪造CSRF，CSRF的破坏力依赖于受害者的权限

CSRF通过伪装来自收信任用户的请求来利用受信任的网站，诱导受害者进行一些敏感的操作

比如向受害者发送一封邮件，诱导受害者进行一些敏感的操作，如修改密码，修改email转账等，而受害者却不知道自己已经中招了。

例如某网站的转账网址是 `www.money.com/moneyto/username`

网站又没做CSRF防御，如果用户点击了别人恶意发送的转账网址就会直接转账过去，因为所有操作都是受害人自己操作的，cookie身份验证完全没问题



​       用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；

​       在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；

​      用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；

​      网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；



**要完成一次CSRF攻击，受害者必须依次完成两个步骤：**

　　1.登录受信任网站A，并在本地生成Cookie。

　　2.在不登出A的情况下，访问危险网站B，B执行一些攻击性代码获取到了cookie，盗取用户身份登录A网站。



## CSRF攻击预防

- 增加确认操作，弹出提示框提示用户当前操作



- 敏感操作重新认证身份如手机验证码等

  

- **验证 HTTP Referer 字段**

  根据 HTTP 协议，**在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址**。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 `www.money.com/moneyto/username`，用户必须先登陆 money.com 后通过点击页面上的按钮来触发转账事件。这时，该转帐请求的 Referer 值就会是转账按钮所在的页面的 URL，通常是以 money.com域名开头的地址。如果服务器发现HTTP请求的 Referer 值来自其他网站就应该把这个请求拦截了。

  但事实上，对于某些浏览器，比如 IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。这样很不安全。

  

- **在请求地址中添加 token 并验证**

  CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。

  Token不存储在cookie中，可以在 每个按钮的HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果URL请求中没有 token 或者 token 内容不正确，说明用户不是自己点击的这个按钮，是恶意站点自己盗取cookie，然后登录网址偷偷进行操作，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token，访问时会在URL后面接上token值。

  

- **在 HTTP 头中自定义属性并验证**

  这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，**可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。**这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。



## 检测CSRF漏洞

检测CSRF漏洞是一项比较繁琐的工作，最简单的方法就是抓取一个正常请求的数据包，去掉Referer字段后再重新提交，如果该提交还有效，那么基本上可以确定存在CSRF漏洞。





